---
title: "Gynecologic Oncology Accessibility Project"
subtitle: "Comprehensive Healthcare Accessibility Analysis Using Isochrone Methodology"
author: 
  - name: "Tyler Muffly, MD"
    affiliation: "Department of Obstetrics and Gynecology"
    email: "tyler.muffly@dhha.org"
date: "`r Sys.Date()`"
description: |
  This project analyzes nationwide access to gynecologic oncologists and other 
  OBGYN subspecialists using drive time isochrones, demographic data, and 
  geospatial analysis. The analysis examines how accessibility varies across 
  different geographic areas, demographic groups, and time periods (2013–2023).
keywords: 
  - "gynecologic oncology"
  - "healthcare accessibility" 
  - "spatial analysis"
  - "isochrones"
  - "health disparities"
  - "geographic information systems"
version: "1.0.0"
license: "MIT"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: 
      collapsed: false
      smooth_scroll: true
    number_sections: true
    theme: "flatly"
    highlight: "tango"
    fig_width: 10
    fig_height: 8
    fig_caption: true
    code_folding: "show"
    code_download: true
    dev: "png"
    dpi: 300
    self_contained: true
    keep_md: true
    pandoc_args: ["--wrap=preserve"]
link-citations: true
always_allow_html: true
editor_options:
  chunk_output_type: console
  markdown:
    wrap: 80
    canonical: true
---

<!-- Custom CSS for enhanced styling -->

```{=html}
<style>
.main-container {
  max-width: 1400px;
}

.equation-box {
  background-color: #f8f9fa;
  border: 1px solid #dee2e6;
  border-radius: 5px;
  padding: 15px;
  margin: 10px 0;
}

.method-box {
  background-color: #e3f2fd;
  border-left: 4px solid #2196f3;
  padding: 15px;
  margin: 10px 0;
}

.results-box {
  background-color: #f3e5f5;
  border-left: 4px solid #9c27b0;
  padding: 15px;
  margin: 10px 0;
}

.code-title {
  background-color: #263238;
  color: white;
  padding: 8px;
  margin-bottom: 0;
  border-radius: 5px 5px 0 0;
  font-weight: bold;
}

.highlight-box {
  background-color: #fff3cd;
  border: 1px solid #ffeaa7;
  border-radius: 5px;
  padding: 15px;
  margin: 10px 0;
}

.technical-note {
  background-color: #d1ecf1;
  border: 1px solid #bee5eb;
  border-radius: 5px;
  padding: 12px;
  margin: 8px 0;
  font-size: 0.9em;
}
</style>
```

```{r source setup}
source("R/01-setup.R")      # provides create_geocode()
```

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  warning = FALSE,
  message = FALSE,
  cache = FALSE
)
```

## Project Overview

This project analyzes nationwide access to gynecologic oncologists and other
OBGYN subspecialists using drive time isochrones, demographic data, and
geospatial analysis. The analysis examines how accessibility varies across
different geographic areas, demographic groups, and time periods (2013-2023).

Using the HERE Maps API and census data, we calculate drive time isochrones
around gynecologic oncologists' locations and analyze the demographics of
populations within each drive time threshold. The project examines changes in
accessibility over time and retirement patterns among specialists.

### Subspecialists Analyzed

-   Female Pelvic Medicine and Reconstructive Surgery/Urogynecology
-   Gynecologic Oncology
-   Maternal-Fetal Medicine
-   Reproductive Endocrinology and Infertility

## Materials and Methods

### Data Sources

**Physician Provider Data**: National Plan and Provider Enumeration System
(NPPES) files from 2013 to 2023 were obtained from the National Bureau of
Economic Research (NBER) cumulative dataset, which provides deduplicated
historical provider records spanning April 2007 to present, addressing
limitations in official CMS offerings that lack historical provider details. The
dataset is deduplicated based on variable changes (excluding mere updates in
file names or years), and includes separate core and multiplicative variable
files to manage large file sizes efficiently.

Additional validation data sources included: - Medicare Part D prescriber data
(2013-2022) for providers treating Medicare patients over 65 years old - CMS
facility affiliation data (2014-present) serving as the "gold standard" for
current practice locations\
- CMS Open Payments data (2013-present) for cross-verification of provider
activity status - NPI deactivation data for tracking provider retirement, though
may lag real-time by 1-2 years due to self-reporting

**Population and Demographic Data**: American Community Survey (ACS) 5-year
estimates and decennial census data provided demographic and population
information. Census block groups were used as the primary geographic unit rather
than counties to achieve higher spatial resolution for accessibility
calculations.

**Geographic Data**: Census TIGER/Line shapefiles provided geographic
boundaries. Rural-Urban Commuting Area (RUCA) codes from the USDA Economic
Research Service were used for rural-urban classification.

### Provider Identification and Classification

Gynecologic oncologists and other OBGYN subspecialists were identified using
National Uniform Claim Committee (NUCC) Healthcare Provider Taxonomy codes. The
analysis searched all taxonomy columns in each year's dataset (not just the
primary taxonomy) to capture physicians with multiple subspecialty
certifications.

```{r, include = FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  echo = TRUE,          # Show code in output
  warning = FALSE,      # No warnings
  message = TRUE,       # Show messages
  error = FALSE,        # Don't stop on errors
  fig.width = 8,        # Default figure width
  fig.height = 6,       # Default figure height
  fig.align = "center", # Center figures
  dpi = 300,            # Higher resolution figures
  out.width = "85%",    # Control display size
  cache = FALSE,        # Cache results? (TRUE for large computations)
  comment = "#>",       # Comment character for output
  tidy = FALSE,         # Don't reformat code
  dev = "png",           # Output device for plots
  include = FALSE
)

# Check if required directories exist
if (!dir.exists("figures")) dir.create("figures", recursive = TRUE)
if (!dir.exists("data")) dir.create("data", recursive = TRUE)
if (!dir.exists("assets")) dir.create("assets", recursive = TRUE)
```

```{r load-packages, include=FALSE, message=FALSE}
# Core data manipulation and analysis
library(tidyverse)
library(logger)
library(assertthat)
library(glue)

# Geospatial analysis
library(sf)
library(tigris)

# Visualization
library(ggplot2)
library(scales)
library(viridis)
library(gghighlight)
library(patchwork)
library(ggtext)
library(ggrepel)

# Tables and reporting
library(DT)
library(knitr)
library(kableExtra)

# Statistical analysis
library(stats)
library(broom)

# Set logger threshold
logger::log_threshold(logger::INFO)

# Set ggplot2 theme
theme_set(theme_minimal(base_size = 12))
```

# ABSTRACT

**Objective:** To quantify changes in accessibility to gynecologic oncology care
across the United States from 2013-2022, with particular attention to
urban-rural disparities, drive time thresholds, and racial/ethnic differences in
access.

**Methods:** We analyzed gynecologic oncologist practice locations combined with
U.S. Census data from 2013-2022. Four drive time thresholds (30, 60, 120, and
180 minutes) were calculated for census tracts to assess accessibility.
Population-weighted mean access rates were determined for urban and rural
populations and stratified by race/ethnicity. Linear regression models with
temporal trend analysis were employed to assess statistical significance of
changes over time.

**Results:** Accessibility to gynecologic oncologists declined significantly
across all time thresholds over the 10-year period. The most pronounced decrease
occurred in 30-minute accessibility (-23.6%, p\<0.001), followed by 60-minute
(-16.8%, p\<0.001), 120-minute (-8.5%, p\<0.01), and 180-minute thresholds
(-2.8%, p\<0.05). Approximately 277.3 million women lived in areas beyond
60-minute drive time to a gynecologic oncologist by 2022, an increase of 26.8
million from 2013. Urban-rural disparities were substantial, with only 10.2% of
rural women having 30-minute access compared to 44.1% of urban women (p\<0.001).
Racial/ethnic disparities were equally pronounced, with Asian women having the
highest access rates (86.5%), followed by Black women (77.2%), Native Hawaiian
and Pacific Islander women (75.3%), and White women (66.8%), while American
Indian and Alaska Native women had dramatically lower access (50.9%, p\<0.001).

**Conclusions:** Access to gynecologic oncology care has significantly
diminished over the past decade, with shorter drive time thresholds experiencing
the steepest declines. Geographic concentration of gynecologic oncologists in
urban academic centers has created substantial access barriers, particularly for
rural communities. Without intervention, these trends will continue to
exacerbate cancer outcome disparities for rural and minority populations.
Strategic initiatives including outreach clinics, telemedicine networks, and
targeted training programs are needed to address the maldistribution of
gynecologic oncologists.

## Yearly Maps Combined

![Yearly Maps Combined](figures/faceted_year_plots/yearly_maps_combined.png)

# 🔬 Research Objectives

-   **Primary**: Quantify geographic accessibility to gynecologic oncology
    specialists nationwide
-   **Secondary**: Analyze demographic disparities in subspecialist access
-   **Tertiary**: Examine temporal trends in healthcare workforce distribution
-   **Quaternary**: Identify underserved populations and geographic areas

# 🎯 Project Overview & Conceptual Framework

This project analyzes nationwide access to gynecologic oncologists and other
OBGYN subspecialists using drive time isochrones, demographic data, and
geospatial analysis. The analysis examines how accessibility varies across
different geographic areas, demographic groups, and time periods (2013-2023).

Using the HERE Maps API and census data, we calculate drive time isochrones
around gynecologic oncologists' locations and analyze the demographics of
populations within each drive time threshold. The project examines changes in
accessibility over time and retirement patterns among specialists.

## What Are Isochrones?

**Isochrone Definition for Census Tracts:**

$$I_t(O) = \{T_i \in \mathcal{T} : d(O, c(T_i)) \leq t\}$$

**Multi-Time Isochrone System:**

$$\mathcal{I} = \bigcup_{t \in \{30, 60, 120, 180\}} I_t(O) \text{ where } I_t(O) = \{T_i : d(O, c(T_i)) \leq t\}$$

**Travel Time Function with Network Constraints:**
$$d(O, c(T_i)) = \min_{p \in P(O, c(T_i))} \sum_{e \in p} \frac{l_e}{v_e}$$

**Complete Isochrone Boundary System:**

$$\begin{align}
I_{30}(O) &= \{T_i \in \mathcal{T} : d(O, c(T_i)) \leq 30\} \\
I_{60}(O) &= \{T_i \in \mathcal{T} : d(O, c(T_i)) \leq 60\} \setminus I_{30}(O) \\
I_{120}(O) &= \{T_i \in \mathcal{T} : d(O, c(T_i)) \leq 120\} \setminus I_{60}(O) \\
I_{180}(O) &= \{T_i \in \mathcal{T} : d(O, c(T_i)) \leq 180\} \setminus I_{120}(O)
\end{align}$$

Where: - $I_t(O)$ = isochrone for time $t$ from origin $O$ - $\mathcal{T}$ = set
of all census tracts - $T_i$ = individual census tract $i$ - $c(T_i)$ = centroid
of census tract $T_i$ - $d(O, c(T_i))$ = shortest travel time from origin to
tract centroid - $P(O, c(T_i))$ = set of all possible paths from $O$ to
$c(T_i)$ - $l_e$ = length of road segment $e$ - $v_e$ = speed on road segment
$e$

This equation system captures how census tracts are assigned to different drive
time zones, creating nested isochrone boundaries at 30, 60, 120, and 180-minute
intervals.

Here's the additional equation for counting accessible population by demographic
groups:

**Accessible Population by Demographics:**

$$A_t^{demo}(O) = \sum_{T_i \in I_t(O)} W_i^{demo}$$

**Total Accessible Women Population by Race/Ethnicity:** $$\begin{align}
A_t^{Total}(O) &= A_t^{White}(O) + A_t^{Black}(O) + A_t^{Asian}(O) \\
&\quad + A_t^{HIPI}(O) + A_t^{Hispanic}(O) + A_t^{Other}(O)
\end{align}$$

**Complete Accessibility Matrix:** $$\mathbf{A}(O) = \begin{bmatrix}
A_{30}^{White}(O) & A_{60}^{White}(O) & A_{120}^{White}(O) & A_{180}^{White}(O) \\
A_{30}^{Black}(O) & A_{60}^{Black}(O) & A_{120}^{Black}(O) & A_{180}^{Black}(O) \\
A_{30}^{Asian}(O) & A_{60}^{Asian}(O) & A_{120}^{Asian}(O) & A_{180}^{Asian}(O) \\
A_{30}^{HIPI}(O) & A_{60}^{HIPI}(O) & A_{120}^{HIPI}(O) & A_{180}^{HIPI}(O) \\
A_{30}^{Hispanic}(O) & A_{60}^{Hispanic}(O) & A_{120}^{Hispanic}(O) & A_{180}^{Hispanic}(O) \\
A_{30}^{Other}(O) & A_{60}^{Other}(O) & A_{120}^{Other}(O) & A_{180}^{Other}(O) \\
\end{bmatrix}$$

**Conditional Population Inclusion:** $$W_i^{demo} = \begin{cases} 
Pop_{women}^{demo}(T_i) & \text{if } d(O, c(T_i)) \leq t \\
0 & \text{if } d(O, c(T_i)) > t
\end{cases}$$

Where: - $A_t^{demo}(O)$ = accessible women population of demographic group
within time $t$ from gynecologic oncologist at origin $O$ - $W_i^{demo}$ = women
population of specific demographic in census tract $T_i$ -
$Pop_{women}^{demo}(T_i)$ = total women population of demographic group in tract
$T_i$ - $demo \in \{White, Black, Asian, HIPI, Hispanic, Other\}$ - HIPI =
Hawaiian and Pacific Islander

This framework quantifies healthcare accessibility disparities by measuring how
many women of each racial/ethnic group can reach gynecologic oncology services
within different drive time thresholds.

## Interactive Isochrone Map

<iframe src="figures/isochrone_map_20240208_181110.html" width="100%" height="600px">

</iframe>

**Isochrones** are geographic boundaries showing areas reachable within specific
travel times from a point. Think of them as "time zones" around each doctor's
office - the 30-minute isochrone includes all places you can drive to within 30
minutes.

**Why This Matters for Healthcare Access:** - **Patient perspective**: How far
do I have to travel for specialized care? - **Policy perspective**: Which
populations are underserved? - **Planning perspective**: Where should new
providers practice?

## Enhanced Census Tract Map

![Enhanced Census Tract Map](figures/enhanced_census_tract_map.png)

## Key Methodological Decisions & Rationale

### Drive Time Thresholds (30, 60, 120, 180 minutes)

-   **30 minutes**: Local/regional access - most patients willing to travel
-   **60 minutes**: Extended local access - reasonable for specialty care
-   **120 minutes**: Regional access - acceptable for highly specialized care
-   **180 minutes**: Maximum reasonable access - beyond this is effectively
    inaccessible

### Reference Time: Third Friday of October, 9:00 AM

-   **Rationale**: Standardized across all years for consistency
-   **Considerations**: Rush hour vs. off-peak; Friday represents typical
    weekday
-   **Limitation**: Doesn't account for seasonal variations or weekend access

### Geographic Resolution: Census Block Groups vs. Counties

-   **Choice**: Used census block groups (smaller geographic units)
-   **Advantage**: More precise population estimates, captures urban/rural
    differences
-   **Trade-off**: Increased computational complexity vs. more accurate results

## Subspecialist Categories Analyzed

### Primary Focus: Gynecologic Oncology

-   **Definition**: Physicians specializing in cancers of the female
    reproductive system
-   **Taxonomy Code**: 207VX0201X
-   **Typical Training**: 3 or 4-year fellowship after OBGYN residency
-   **Rarity**: Highly specialized - limited number nationwide

### Secondary Analysis Subspecialties:

1.  **Female Pelvic Medicine/Urogynecology (207VF0040X)**
    -   Pelvic floor disorders, incontinence
    -   Recent name change from FPMRS to URPS
2.  **Maternal-Fetal Medicine (207VM0101X)**
    -   High-risk pregnancy specialists
    -   Critical for complex obstetric care
3.  **Reproductive Endocrinology (207VE0102X)**
    -   Fertility specialists
    -   Hormone-related reproductive disorders

#### Taxonomy Code Reference

``` r
obgyn_taxonomy_codes <- c(
  "207V00000X",    # Obstetrics & Gynecology (general)
  "207VX0201X",    # Gynecologic Oncology (PRIMARY FOCUS)
  "207VE0102X",    # Reproductive Endocrinology 
  "207VG0400X",    # Gynecology (general)
  "207VM0101X",    # Maternal & Fetal Medicine
  "207VF0040X",    # Female Pelvic Medicine/Urogynecology
  "207VB0002X",    # Bariatric Medicine
  "207VC0200X",    # Critical care medicine
  "207VC0040X", 
  "207VC0300X",    # Complex family planning  
  "207VH0002X",    # Palliative care
  "207VX0000X"     # Obstetrics only
)
```

### Quality Control and Data Validation

The `check_physician_presence` function was implemented as a quality control
utility for tracking physicians across temporal data. This function efficiently
analyzes datasets containing physician information to determine when specific
providers appear in records, accepting National Provider Identifiers (NPIs) and
methodically examining each NPI's presence throughout different years. It
returns structured data summarizing each provider's representation, including
total record count and chronological listing of years present.

``` r
# Example validation list of known NPIs for quality control
=======
## 📂 Detailed File Organization & Purpose
```

isochrones/ ├── 📁 data/ \# Raw and processed datasets │ ├──
demographic_disparities_analysis.csv │ ├── difference_in_difference_analysis.csv
│ ├── duplicateyearandfill.csv │ ├──
end_inner_join_postmaster_clinician_data.csv │ ├──
end_rejoined_geocoded_unique_address.csv │ ├── fips-states.csv │ ├──
healthcare_benchmark_references.md │ ├── intersect.csv │ ├──
Medicare_Part_D_physician_retirement_analysis.csv │ ├──
physician_compare_data.csv │ ├── physician_retirement_years.csv │ ├──
population_weighted_means_with_ci.csv │ └── racial_decay_curves.png ├── 📁
figures/ \# Generated visualizations │ └── [Generated plots and maps] ├── 📁 R/
\# All R scripts and functions │ │ 👩️ ***GO_access_analysis_code.Rmd*** \# Main
analysis report │ ├── 📊 Data Collection (A-Series) │ │ ├── A-abms.R \# Board
certification scraping │ │ ├── A-facility_affiliation_download.R \# CMS facility
data │ │ ├── A-Medicare_part_d_prescribers_data_download.R │ │ ├──
A-NPI_deactivation_download.R \# Provider deactivation │ │ ├──
A-nppes_download.R \# Historical NPPES from NBER │ │ ├──
A-open_payments_download.R \# Sunshine Act data │ │ └──
A-physician_compare_data_download.R │ ├── 📋 Data Read In (B-Series) │ │ ├──
B-Medicare_part_d_prescribers_read_in.R \# Read in data │ │ ├──
B-NPI_deactivation.R \# Read in data │ │ ├──
B-NPPES_read_in_csv_to_duckDB_database.R \# Read in data │ │ ├──
B-open_payments_cleaning.R \# Read in data │ │ ├──
B-physician_compare_data_download.R \# Read in data │ ├── 📋 Data Processing
(C-Series) │ │ ├── C-Extracting_and_Processing_NPPES_Provider_Data.R │ │ ├──
C-NPPES.R │ │ ├── C-open_payments.R │ │ ├── C-physician_compare_cleaning.R │ ├──
📋 Data Quality Check (D-Series) │ │ ├── D-Quality_check_medicare_prescribing.R
│ │ ├── D-Quality_check_on_NPPES_merge.R │ ├── 📋 Export Cleaned Data (E-Series)
│ │ ├── E-Medicare_part_d_retirement_analysis_processing.R │ │ ├──
E-open_payments_export.R │ │ └── F-retirement_year_confirmation.R │ ├── 🗺️ Core
Analysis Pipeline (00-10 Series) │ │ ├── 000-Control.R \# Master control script
│ │ ├── 01-setup.R \# Environment and API setup │ │ ├── 02-search_taxonomy.R \#
NPPES taxonomy search │ │ ├── 02.5-subspecialists_over_time.R \# Temporal trends
│ │ ├── 03-search_and_process_npi.R \# NPI data processing │ │ ├──
03a-search_and_process_extra.R \# Additional NPI processing │ │ ├── 04-geocode.R
\# Address geocoding (HERE API) │ │ ├── 06-isochrones.R \# Drive time isochrone
generation │ │ ├── 07-isochrone-mapping.R \# Spatial joins and mapping │ │ ├──
07.5-prep-get-block-group-overlap.R │ │ ├── 08-get-block-group-overlap.R \#
Census block calculations │ │ ├── 08.5-prep-the-census-variables.R │ │ ├──
09-get-census-population.R \# Population analysis │ │ ├──
10-calculate-polygon-demographics.R │ │ └── 10-make-region.R \# Regional
analysis │ ├── 📈 Results & Analysis │ │ ├── analyze_isochrone_data.R \#
Statistical trend analysis │ │ ├── walker_isochrone_maps.R \# Final map
generation │ │ ├── subspecialists_over_time.R \# Workforce trends │ │ ├──
retirement_adjusted.R \# Retirement analysis │ │ └── getting_isochrones_trying.R
\# Alternative methods │ ├── 🛠️ Utility Functions │ │ ├── api_keys.R \# API key
management │ │ ├── bespoke_functions.R \# Custom project functions │ │ ├──
geocode.R \# Geocoding utilities ├── 📁 results/ \# Analysis outputs │ ├──
state_data.csv │ ├── summary_statistics.csv │ ├──
table1_temporal_trends_summary.csv │ ├──
table2_demographic_disparities_summary.csv │ ├──
tabulated_all_years_clean_2024-08-30.xlsx │ ├── temporal_trend_analysis.csv │
├── trend_analysis.csv │ └── us_states.csv ├── 📄 README.Rmd \# This
documentation ├── 📄 README.html \# Rendered HTML version

```         

#### Data Gathering

-   `bespoke_functions.R` - Data for the duckDB connection and functions for the
    Data Gathering lettered code below. The National Bureau of Economic Research
    (NBER) provides a cumulative NPI/NPPES dataset created from monthly CMS
    files spanning from April 2007 to the present, addressing limitations in
    official CMS offerings that lack historical provider details. The dataset is
    deduplicated based on variable changes (excluding mere updates in file names
    or years), and includes separate core and multiplicative variable files to
    manage the large file sizes efficiently.

| **Dataset/Script Name** | **Available Years** | **Notes** |
|:---|:---|:---|
| **`A_nppes_download.R`** | 2007–2022 | NBER cumulative NPPES file (monthly updates deduplicated; includes changes back to 2007). |
| **`A-NPI_deactivation_download.R`** | Varies, slightly delayed | Based on self-reported deactivation. CMS updates irregularly; may lag real-time by 1–2 years. |
| **`A-Medicare_part_d_prescribers_data_downloaded`** | 2013–2022 | Released annually by CMS; first available dataset based on 2013 prescribing data. |
| **`A-download_physician_compare_download`** | \~2013–2020 (downloaded files) | ICPSR archive has files through \~2020 (Physician Compare closed in Dec 2020). Must manually log in. |
| **`A-facility_affiliation_download.R`** | 2014–present | First Facility Affiliation data started \~2014; yearly updates (CMS Physician Compare Affiliation data). |
| **`A-open_payments_download.R`** | 2013–present | Open Payments (Sunshine Act) started reporting payments in 2013. Annual updates. |

-   `A_nppes_download.R` - Downloads NPPES data for back years from NBER
    (National Board Economic Research). The National Bureau of Economic Research
    (NBER) provides a cumulative NPI/NPPES dataset created from monthly CMS
    files spanning from April 2007 to 2022, addressing limitations in official
    CMS offerings that lack historical provider details. The dataset is
    deduplicated based on variable changes (excluding mere updates in file names
    or years), and includes separate core and multiplicative variable files to
    manage the large file sizes efficiently.

-   `A-NPI_deactivation_download.R` - NPPES data may be a few years behind and
    is all based on personal report.

-   `A-Medicare_part_d_prescribers_data_downloaded` - Good for docs who
    prescribe drugs to Medicare patients over 65 years old. Started 2013 to

    2022. 

-   `A-download_physician_compare_download` - To get old physician
    compare/national downloadable files we need to log in manually to OPEN
    ICPSR:
    <https://www.openicpsr.org/openicpsr/project/149961/version/V1/view?path=/openicpsr/149961/fcr:versions/V1&type=project>.
    You have to login with google account to download it.

-   `A-facility_affiliation_download.R` - Gold standard.

-   `A-open_payments_download.R` - Open Payments.

-   `B-read_in_csv_file_to_duckDB_database.R` - Reads in the NPPES CSV fils from
    the NBER to the duckDB database. The primary action occurs via the
    process_nppes_data function (defined in an external script
    bespoke_functions.R), which reads and processes a large CSV file containing
    historical NPI data (spanning May 2005 to October 2020). The processed data
    is stored in a DuckDB database file.

-   `C-Extracting_and_Processing_NPPES_Provider_Data.R` - Function for
    processing OBGYNs from NPPES data with exact file names for years 2010
    to 2022. Automatically identifies and maps database tables to their
    corresponding years, enabling efficient extraction of provider data across
    different time periods. Specifies taxonomy codes representing various OB/GYN
    subspecialties, including general obstetrics and gynecology, maternal-fetal
    medicine, and female pelvic medicine. Looks at all taxonomy columns in each
    year's dataset (not just the first one). Checks if any of your specified
    codes appear in any of those columns. Includes a physician in the results if
    there's a match in any column. Retrieves provider records matching specified
    OB/GYN taxonomy codes from each year, standardizing and combining the data
    into a unified dataset.

-   `D-Quality_check_on_NPPES_merge.R` - The check_physician_presence function
    is a well-designed utility for tracking physicians across temporal data. It
    efficiently analyzes a dataset containing physician information to determine
    when specific providers appear in the records. The function accepts a list
    of National Provider Identifiers (NPIs), optionally paired with provider
    names, and methodically examines each NPI's presence throughout different
    years. It returns a structured data frame summarizing each provider's
    representation in the dataset, including their total record count and a
    chronological listing of years in which they appear. This function is
    particularly valuable for longitudinal analyses of healthcare provider data,
    enabling researchers to identify patterns in physician presence, track
    career trajectories, or validate data completeness across multiple years of
    NPI records.

```r
# List of NPIs to check
npi_list <- c(
  "1689603763",   # Tyler Muffly, MD
  "1528060639",   # John Curtin, MD
  "1346355807",   # Pedro Miranda, MD
  # ... additional validation cases
)
```

### Geocoding and Address Standardization

Provider practice addresses were geocoded using the HERE Maps Geocoding API
(version 6.2). Addresses were standardized and cleaned prior to geocoding, with
quality scoring and manual review of poor matches. Coordinate validation
included bounds checking and outlier detection.

### Isochrone Generation and Spatial Analysis

Drive time isochrones were calculated using the HERE Maps Isoline Routing API
(version 7.2) with the following specifications:

-   **Time Thresholds**: 30, 60, 120, and 180 minutes
-   **Reference Time**: Third Friday of October at 9:00 AM local time for each
    analysis year (2013-2023)\
-   **Vehicle Type**: Car
-   **Traffic Conditions**: Real-time traffic enabled
-   **Route Quality**: Highest quality setting

The reference time was standardized across all years to ensure temporal
consistency, selected to represent typical weekday travel conditions while
avoiding rush hour peaks.

### Demographic and Population Analysis

Population within each isochrone was calculated through spatial intersection of
drive time polygons with census block groups. Area-weighted population estimates
were computed for partial block group overlaps.

**Primary Analysis Population**: Female population, with demographic
stratification by: - Race/ethnicity: White alone, Black or African American
alone, Asian alone, American Indian and Alaska Native alone - Geographic
regions: American College of Obstetricians and Gynecologists (ACOG) Districts -
Rural-urban classification: RUCA codes

### Statistical Analysis

Temporal trends in accessibility were analyzed using linear regression to
measure changes from 2013 to 2022. Statistical significance was assessed at p \<
0.05. Slope calculations, R-squared values, and p-values were computed for each
demographic category and drive time threshold.

## Results

### Overall Access to Gynecologic Oncologists

**Baseline Access (2013)**: Among the total female population, 72.4 million
women (44.5% of total population) had access to gynecologic oncologists within a
30-minute drive time. Access increased with longer drive times: 98.3 million
women (60.4%) within 60 minutes, 133.0 million women (81.8%) within 120 minutes,
and 148.4 million women (91.3%) within 180 minutes.

**Current Access (2022)**: Access levels remained relatively stable, with 71.6
million women having 30-minute access, 97.7 million women having 60-minute
access, 132.9 million women having 120-minute access, and 148.4 million women
having 180-minute access.

``` r
# Example access data structure
=======
  "1437904760",   # Lizeth Acosta, MD
  "1568738854",   # Aaron Lazorwitz, MD
  "1194571661",   # Ana Gomez, MD
  "1699237040",   # Erin W. Franks, MD
  "1003311044",   # CATHERINE Callinan, MD
  "1609009943",   # Kristin Powell, MD
  "1114125051",   # Nathan Kow, MD
  "1043432123",   # Elena Tunitsky, MD
  "1215490446",   # PK
  "1487879987"    # Peter Jeppson
)
```

-   `E-Medicare_part_d_prescribers_data_processing.R` - This script processes
    Medicare Part D prescribing data from the Centers for Medicare & Medicaid
    Services (CMS). Process each table filtering "Prscrbr_Type" only OBGYN and
    "Gynecological Oncology". It identifies providers' prescribing patterns,
    cleans data by removing outlier records (claim counts over 50,000),
    annotates records by year, and merges multiple years into a single
    standardized dataset. Additionally, it calculates the last consecutive year
    each provider actively prescribed medications under Medicare Part D,
    facilitating analysis of provider activity and continuity over time. NOT
    GOOD FOR DOCS WHO DO NOT TREAT PATIENTS \>65 years old.

-   `F-retirement_year_confirmation.R` - Download the massive data files to the
    external hard drive for this with one set of code then then can run
    E-retirement_year_confirmation.R.

Retirement Year Data download: `NPPES_deactivated_download.R` - Best source but
may be late.\
`Medicare_part_d_prescribers_data_processing` - People who prescribed to \>65
year old women.\
`download_physician_compare_data.R` - Includes data for people who see
Medicare.\
facility affiliation. - Does not include a year for the facility affiliation so
it is not helpful.\
ABMS - scraped.

-   `getting_isochrones_trying.R` - Alternative method for isochrone generation
-   `retirement_adjusted.R` - Enhanced retirement analysis using multiple data
    sources (NPI deactivation, Medicare data, and board certification status) to
    improve workforce accuracy.
-   `subspecialists over time.R` - Analysis of subspecialist trends
-   `visualize_fips_inters_isochr.R` - Visualizes FIPS code intersections
-   `fips_blocks_female_proportion.R` - Analyzes female population in FIPS
    blocks
-   `fips_isochrones_population_intersect.R` - Examines population within
    isochrones
-   `zzzPostico.R` - Used Postico originally. Able to use duckDB later on.\
-   `Postico_database_pull.R` - Extracts physician data from PostgreSQL
    database, enabling year-by-year analysis of physician practice locations
    from 2013 to 2022. Pulls "GYNECOLOGIC ONCOLOGY" from the Primary Specialty.
    For urogyn, we will need NPIs to go retrospectively to look for people.

#### 1. Setup and Data Preparation

-   `000-control.R` - Auxiliary script for data compilation
-   `01-setup.R` - Loads packages, sets API keys, defines helper functions,
    initializes directory structure
-   `02-search_taxonomy.R` - Search the NPPES Registry database using npi_search
    library in a wrapper. Taxonomy description from the NUCC:
    <https://taxonomy.nucc.org/>. Note recent change in FPMRS to URPS.\
-   `02.5-subspecialists_over_time.R` - Analyzes subspecialist trends over
    multiple years
-   `03-search_and_process_npi.R` - Processes National Provider Identifier (NPI)
    data
-   `03a-search_and_process_extra.R` - Additional NPI processing for edge cases
-   `04-geocode.R` - Geocodes provider addresses using the HERE API
-   `zz05-geocode-cleaning.R` - Old technique with postmaster pulling apart the
    address.

#### 2. Isochrone Generation and Analysis

-   `06-isochrones.R` - Generates drive time isochrones (30, 60, 120, 180 min)
-   `07-isochrone-mapping.R` - Maps isochrones and performs spatial joins
-   `07.5-prep-get-block-group-overlap.R` - Prepares census block group data
-   `08-get-block-group-overlap.R` - Calculates overlap between isochrones and
    census blocks
-   `08.5-prep-the-census-variables.R` - Prepares demographic variables from
    Census
-   `09-get-census-population.R` - Calculates population within/outside
    isochrones

#### 3. Results and Analysis

-   `10-calculate-polygon-demographics.R` - Analyzes demographic characteristics

-   `10-make-region.R` - Creates regional maps and analyses

-   `analyze_isochrone_data.R` - Framework for analyzing isochrone data

-   `calculate_population_in_isochrones_by_race.R` - Analyzes population by race
    within isochrones

-   `walker_isochrone_maps.R` - Visualizes isochrone changes over time

-   `Access_Data.csv` - Data from Tannous that he arranged and is held in
    `data/`

### R Markdown Documents

-   `GO_access_analysis_code.Rmd` - Statistical analysis of gynecologic oncology
    access
-   `for_every_year_script_rmd.Rmd` - Year-by-year analysis of accessibility
    trends
-   `isochrones.Rmd` - Tutorial on creating and analyzing isochrones

## Execution Order

For a complete analysis, the files should be executed in approximately this
order:

### Setup Phase

1.  `01-setup.R`
2.  `Postico_database_pull.R` (if external hardrive with the Positico database
    access is connected)

### Data Collection Phase

3.  `02-search_taxonomy.R`
4.  `02.5-subspecialists_over_time.R`
5.  `03-search_and_process_npi.R` - When did physicians start practicing?
6.  `03a-search_and_process_extra.R`
7.  `04-geocode.R`
8.  `zz05-geocode-cleaning.R`
9.  `retirement.R`/`retirement_adjusted.R` - When did physicians retire? (if
    physician retirement analysis is needed)

### Isochrone Analysis Phase

9.  `06-isochrones.R`
10. `07-isochrone-mapping.R`
11. `07.5-prep-get-block-group-overlap.R`
12. `08-get-block-group-overlap.R`
13. `08.5-prep-the-census-variables.R`
14. `09-get-census-population.R`

### Results and Additional Analysis Phase

15. `10-calculate-polygon-demographics.R`

16. `10-make-region.R`

17. `script2025.R` - Downloads the population data and aggregates it by
    isochrone and by total population. Creates tables of women within isochrones
    and total women.\

``` r
> access_merged
# A tibble: 240 × 6
   year  range category              count     total percent
   <chr> <int> <chr>                 <dbl>     <dbl>   <dbl>
 1 2013   1800 total_female       72362517 162649954    44.5
 2 2013   1800 total_female_white 46553359 119180751    39.1
```

### Temporal Trends in Access (2013-2022)

Statistical analysis of temporal trends revealed significant variations by
demographic group:

**Total Female Population**: Showed declining trends across all drive time
thresholds, though not all reached statistical significance: - 30-minute access:
-736,396 women per year (R² = 0.113, p = 0.343) - 60-minute access: -630,107
women per year (R² = 0.072, p = 0.453)\
- 120-minute access: -134,072 women per year (R² = 0.005, p = 0.854) -
180-minute access: -3,016 women per year (R² \< 0.001, p = 0.997)

**Racial/Ethnic Disparities**: - **White women**: Significant declines in access
observed across all time thresholds - **Asian women**: Significant increases in
longer drive time access (120+ minutes) - **American Indian/Alaska Native
women**: Mixed trends with some increases in 30- and 60-minute access
categories, though starting from lower baseline access levels

``` r
=======
19. `analyze_isochrone_data.R` - Measures the slope for access from start 2013
    to finish 2022. Finds significant increases or decreases in the number of
    women within a drive time. Some notable trends:

-   Total female white population shows significant declines in access across
    all time thresholds
-   Some categories like `total_female_asian` show significant increases in
    longer-time thresholds

$$
    R^2 = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{\sum_i (y_i - \hat{y}_i)^2}{\sum_i (y_i - \bar{y})^2}
$$

``` r
> isochrone_results$trend_analysis
                 category        time_threshold         slope    r_squared     p_value start_year end_year start_value
year         total_female  access_30min_cleaned -7.363956e+05 1.126669e-01 0.343029928       2013     2022    72362517
year1        total_female  access_60min_cleaned -6.301068e+05 7.221735e-02 0.452792176       2013     2022    98337640
year2        total_female access_120min_cleaned -1.340719e+05 4.509434e-03 0.853764926       2013     2022   133049027
year3        total_female access_180min_cleaned -3.015709e+03 2.336200e-06 0.996656494       2013     2022   148447072
year4   total_female_aian  access_30min_cleaned  8.242703e+03 1.559138e-01 0.258786159       2013     2022      316937
year5   total_female_aian  access_60min_cleaned  1.109027e+04 1.747050e-01 0.229364327       2013     2022      453807
```

### Geographic Patterns

Analysis revealed persistent rural-urban divides and regional variations in
access to gynecologic oncology care. Geographic regions with highest access
density included major metropolitan areas and academic medical centers, while
rural and frontier areas showed significantly reduced access across all time
thresholds.

```{r}
# Load required packages for README generation
library(knitr)
library(kableExtra)
library(DT)
library(plotly)
```

# Project Overview {.tabset}

## Overview

::: highlight-box
**Mission**: This project provides the most comprehensive analysis of nationwide
access to gynecologic oncologists and OBGYN subspecialists using advanced
**drive time isochrone methodology**, **demographic stratification**, and
**longitudinal geospatial analysis**.
:::

This research examines healthcare accessibility disparities across: -
**Geographic dimensions** (urban/rural, regional variations) - **Demographic
stratifications** (race, ethnicity, socioeconomic status) - \*Temporal dynamics
**(2013-2023 longitudinal trends) -** Travel time thresholds\*\* (30, 60, 120,
180-minute drive times)

# 📁 NBER NPPES Data

This project uses **National Plan and Provider Enumeration System (NPPES)** data
as released by the **National Bureau of Economic Research (NBER)**, which
provides historical snapshots of the NPPES downloadable files.

### 📌 Data Source

The files were downloaded from the NBER’s archival repository of NPPES datasets:
🔗
[https://data.nber.org/npi/zip/](https://www.nber.org/research/data/national-plan-and-provider-enumeration-system-nppes)

## 📊 **Expected Results (Based on Directory Listings):**

| Year | File You'll Get | Month | Notes |
|----|----|----|----|
| 2007 | `npi200711.csv` | November | Only monthly file available |
| 2008 | `npidata_20050523-20080512.csv` | Annual | No monthly files |
| 2009 | `npi20094.csv` | **April** ✅ | Perfect! |
| 2010 | `npidata_20050523-20100111.csv` | Annual | No monthly files |
| 2011 | `npi20114.csv` | **April** ✅ | Perfect! |
| 2012 | `npi20124.csv` | **April** ✅ | Perfect! |
| 2013 | `npi20133.csv` | March | April missing, March fallback |
| 2014 | `npi20142.csv` | February | April missing, Feb fallback |
| 2015-2019 | `npi2015X4.csv` etc. | **April** ✅ | All have April |
| 2020-2023 | `npi2020X4.parquet` etc. | **April** ✅ | Parquet format |

## 🎉 **You'll Get 17 Years of Data:**

-   **10+ years with actual April data** (2009, 2011, 2012, 2015-2023)
-   **Close months for missing April** (2007=Nov, 2013=Mar, 2014=Feb)
-   **Annual consolidated files** for years without monthly data (2008, 2010)

### ✅ Files Used

The file naming patterns are inconsistent across years
(<https://data.nber.org/npi/webdir/csv/2023/>):

2018 and earlier: core20184.csv (month as number, April = 4) 2020-2022:
core20214.csv (month as number, April = 4) 2023: core_April_2023.csv (explicit
month name)

### 🧹 Deduplication and Rationale

-   Duplicate and redundant files (e.g., multiple snapshots within the same
    year) were removed to streamline processing and conserve storage.
-   Files with the same extract date but different filenames (e.g.,
    `npi_data_pfile_20050523-20220410.csv` and
    `NPPES_Data_Dissemination_April_2022_...`) were deduplicated.
-   The selection process prioritized **temporal consistency**, with April being
    used as a standard reference point for yearly comparison.

--------------------------------------------------------------------------------

### 📊 Use Case

These deduplicated files serve as the foundational input for:

-   Identifying actively practicing OBGYNs each year,
-   Constructing a longitudinal DuckDB dataset,
-   Assessing trends in geographic and specialty access to obstetric and
    gynecologic care across the U.S.

--------------------------------------------------------------------------------

Let me know if you’d like to append a citation format or include SHA256 hashes
for integrity verification.

### Key Innovation

Using the **HERE Maps API** combined with **high-resolution census data**, we
calculate precise drive time isochrones around specialist locations and perform
**area-weighted demographic analysis** of populations within each accessibility
threshold.

# HERE API and hereR Package Integration

## Overview

This gynecologic oncology accessibility analysis leveraged the HERE Location
Services API through the `hereR` R package to calculate realistic drive time
isochrones around gynecologic oncologist subspecialist practices. The
implementation consisted of three main phases utilizing enterprise-grade routing
and geospatial analysis capabilities with temporal traffic awareness.

## Phase 0: National Provider Identifier (NPI) Database Processing

### Identifying Gynecologic Oncologists

*Source: `R/03-search_and_process_npi.R`*

The analysis began by identifying gynecologic oncologists from the National
Provider Identifier (NPI) database. The NPI database contains comprehensive
provider information including subspecialty classifications, practice locations,
and credentials.

```{r npi-processing, eval=FALSE, echo=TRUE}
# Process NPI database to identify gynecologic oncologists
subspecialists_data <- readr::read_csv("data/03-search_and_process_npi/subspecialists_only.csv")

# Display sample of gynecologic oncologist data
subspecialists_sample <- subspecialists_data %>%
  dplyr::slice_head(n = 10)

DT::datatable(
  subspecialists_sample,
  caption = "Sample Gynecologic Oncologists from NPI Database Processing",
  options = list(
    pageLength = 10,
    scrollX = TRUE,
    dom = 'Bfrtip',
    buttons = c('copy', 'csv', 'excel')
  ),
  extensions = 'Buttons',
  rownames = FALSE
)
```

The NPI database processing identified gynecologic oncologists through: -
**Taxonomy codes**: Specific subspecialty classifications for gynecologic
oncology - **Credential verification**: Board certification in gynecologic
oncology\
- **Practice validation**: Active practices with complete address information -
**Duplicate removal**: Ensuring unique provider-location combinations

## Why HERE API Over Alternatives

HERE API was selected for this analysis because it provides **historical traffic
data** and allows specification of exact dates and times for routing
calculations. This temporal capability was essential for:

-   Analyzing accessibility patterns across multiple years (2013-2022)
-   Accounting for traffic variations on specific dates
-   Ensuring consistent peak-hour analysis (Friday 9 AM conditions)
-   Comparing year-over-year accessibility changes under similar traffic
    conditions

Alternative APIs lack this temporal specificity, making them unsuitable for
longitudinal healthcare accessibility studies.

## Phase 1: Geocoding Gynecologic Oncologist Practices

### Address Preparation and Google Geocoding Strategy

*Source: `R/04-geocode.R`*

The analysis began by geocoding gynecologic oncologist addresses using
**complete street addresses** rather than ZIP codes alone. This approach was
critical for spatial accuracy in healthcare accessibility analysis.

```{r address-preparation, eval=FALSE, echo=TRUE}
readr::read_rds("data/03-search_and_process_npi/end_complete_npi_for_subspecialists.rds") %>%
  tidyr::unite(address, city, state, zip, sep = ", ", remove = FALSE, na.rm = FALSE) %>%
  readr::write_csv(., "data/04-geocode/for_street_matching_with_HERE_results_clinician_data.csv")
```

### Geocoding Implementation

*Source: `R/04-geocode.R`*

```{r geocoding-implementation, eval=FALSE, echo=TRUE}
csv_file <- "data/04-geocode/for_street_matching_with_HERE_results_clinician_data.csv"
geocoded_data <- create_geocode(csv_file)  # Custom function using Google Geocoding API
write_csv(geocoded_data, "data/04-geocode/end_completed_clinician_data_geocoded_addresses_12_8_2023.csv")

# Validation of geocoding accuracy
mean(geocoded_data$score) # Accuracy assessment
```

### Why Full Addresses vs. ZIP Code Geocoding

**Full Address Advantages:** - **Spatial precision**: Street-level accuracy
(\~10-50 meter precision) vs. ZIP centroid (\~1-5 km precision) - **Clinical
relevance**: Patients navigate to specific medical buildings, not ZIP code
centers - **Urban accuracy**: Critical in dense medical districts where multiple
practices exist within single ZIP codes - **Accessibility modeling**: Drive time
calculations require precise origin points for realistic routing

**ZIP Code Limitations:** - **Spatial aggregation error**: ZIP centroids may be
miles from actual practice locations - *Example*: In Denver ZIP 80218, the
geographic centroid falls in City Park, while gynecologic oncologists practice
3+ miles away at Presbyterian/Saint Joseph Hospital on the ZIP's periphery -
**Urban bias**: ZIP centroids often fall in geographic centers, not
population-weighted centers - *Example*: Manhattan ZIP 10065 centroid falls in
Central Park (unpopulated), while actual gynecologic oncology practices cluster
near populated areas along York Avenue and East End Avenue - **Accessibility
overestimation**: Patients may appear to have access when the actual practice is
significantly farther - *Example*: A patient in Boulder ZIP 80302 appears to
have 15-minute access based on ZIP centroid calculations, but the actual
gynecologic oncologist practice is 25+ minutes away due to the centroid falling
in downtown Boulder while the practice is located on the eastern edge near
Foothills Hospital - **Medical district distortion**: Hospital complexes and
medical centers span multiple ZIP codes - *Example*: The University of Colorado
Anschutz Medical Campus spans ZIPs 80045 and 80238, with gynecologic oncologists
in the same building having different ZIP codes, creating artificial
accessibility boundaries that don't reflect clinical reality

The geocoding achieved high spatial accuracy with quality metrics assessed
using:

$$\text{Geocoding Accuracy} = \bar{S} = \frac{1}{n}\sum_{i=1}^{n} s_i$$

where $s_i$ represents the Google Geocoding API confidence score for each
geocoded gynecologic oncologist address $i$.

## Phase 2: Isochrone Generation

### Mathematical Definition of Healthcare Isochrones

For each gynecologic oncologist practice $g$, isochrones represent drive time
accessibility zones:

$$I_{g,t} = \{p \in \mathbb{R}^2 : T(g, p) \leq t\}$$

where $T(g, p)$ represents the drive time from gynecologic oncologist $g$ to
population point $p$, and $t \in \{30, 60, 120, 180\}$ minutes.

### Isochrone Visualization

```         
    Gynecologic Oncologist Practice (●)
            │
    ┌───────┼───────┐
    │   30 min      │     ← Immediate access zone
    │   ┌───┼───┐   │
    │   │60 min │   │     ← Regional access zone  
    │   │ ┌─┼─┐ │   │
    │   │ │120│ │   │     ← Extended access zone
    │   │ │min│ │   │
    │   │ │180│ │   │     ← Maximum reasonable access
    │   │ │min│ │   │
    │   │ └─┼─┘ │   │
    │   └───┼───┘   │
    └───────┼───────┘

    Areas reachable within:
    ■ 30 minutes  (immediate access)
    ■ 60 minutes  (reasonable access) 
    ■ 120 minutes (extended access)
    ■ 180 minutes (maximum access)
```

### Implementation Parameters

*Source: `R/06-isochrones.R`*

``` r
# Temporal analysis across multiple years for longitudinal study
iso_datetime_yearly <- c("2013-10-18 09:00:00", "2014-10-17 09:00:00", "2015-10-16 09:00:00",
  "2016-10-21 09:00:00", "2017-10-20 09:00:00", "2018-10-19 09:00:00",
  "2019-10-18 09:00:00", "2020-10-16 09:00:00", "2021-10-15 09:00:00",
  "2022-10-21 09:00:00")

isochrones_sf <- process_and_save_isochrones(
  input_file_no_error_rows, 
  chunk_size = 25, 
  iso_datetime = "2023-10-20 09:00:00",
  iso_ranges = c(30*60, 60*60, 120*60, 180*60),  # Convert minutes to seconds
  crs = 4326, 
  transport_mode = "car",
  file_path_prefix = "data/06-isochrones/isochrones_"
)
```

### Error Handling and Validation

*Source: `R/06-isochrones.R`*

```{r error-handling, eval=FALSE, echo=TRUE}
# Pre-validation to prevent batch processing failures
errors <- test_and_process_isochrones(input_file)
input_file_no_error_rows <- input_file %>%
  dplyr::filter(!id %in% error_rows)

# Calculate total expected isochrone features
nrow(input_file_no_error_rows) * 4  # 4 time thresholds per practice
```

The total number of isochrone features generated follows:

$N_{total} = N_{gynecologic oncologists} \times N_{thresholds} = N_{gynecologic oncologists} \times 4$

### Spatial Validation and Clipping

*Source: `R/06-isochrones.R`*

```{r spatial-validation, eval=FALSE, echo=TRUE}
# Clip isochrones to USA borders for analysis boundary
usa_borders <- rnaturalearth::ne_states(country = "United States of America", returnclass = "sf") %>%
  sf::st_set_crs(4326)

isochrones_sf_clipped <- sf::st_intersection(isochrones_df, usa_borders) %>%
  dplyr::arrange(desc(rank))  # Important for proper layering

# Geometry validation for robust spatial analysis
isochrones_sf_clipped <- sf::st_make_valid(isochrones_sf_clipped)
```

## Phase 3: Spatial Analysis and Population Accessibility

### Spatial Join Implementation

*Source: `R/07-isochrone-mapping.R`*

```{r spatial-join, eval=FALSE, echo=TRUE}
# Prepare gynecologic oncologist point locations
subspecialists_lat_long_copy <- subspecialists_lat_long %>%
  sf::st_as_sf(coords = c("long", "lat")) %>%
  sf::st_set_crs(4326) %>%
  distinct(address, .keep_all = TRUE)

# Perform spatial join between practices and their service areas
result <- sf::st_join(
  end_isochrones_sf_clipped, 
  subspecialists_lat_long_copy, 
  left = FALSE, 
  suffix = c("_subspecialists_lat_long", "_isochrones")
)
```

### Population Accessibility Calculation

Population accessibility for gynecologic oncology services was calculated as:

$$A_{d,t} = \frac{P_{d,t}}{P_{d,total}} \times 100\%$$

where: - $A_{d,t}$ = accessibility percentage for demographic group $d$ within
time threshold $t$ - $P_{d,t}$ = population of demographic group $d$ within $t$
minutes of gynecologic oncologist - $P_{d,total}$ = total population of
demographic group $d$

### Technical Implementation Challenges

*Source: `R/06-isochrones.R` and `R/07-isochrone-mapping.R`*

1.  **API Rate Limiting**: Processed in chunks of 25 gynecologic oncologist
    locations per batch
2.  **Temporal Consistency**: Used identical Friday 9 AM timestamps across
    analysis years\
3.  **Error Recovery**: Pre-validation prevented batch failures from problematic
    addresses
4.  **Memory Management**: Applied strategic garbage collection for large
    spatial operations
5.  **Geometry Validation**: Ensured spatial integrity through validation and
    simplification

```{r memory-management, eval=FALSE, echo=TRUE}
# Memory management for large spatial operations
invisible(gc())

# Geometry simplification while preserving topology
subspecialists_lat_long_copy <- sf::st_simplify(subspecialists_lat_long_copy, 
                                               preserveTopology = TRUE, 
                                               dTolerance = 1000)  # 1km tolerance
```

## Visualization and Quality Assurance

### Interactive Mapping Validation

*Source: `R/07-isochrone-mapping.R`*

```{r interactive-mapping, eval=FALSE, echo=TRUE}
# Create validation map showing gynecologic oncologist locations and service areas
isochrone_map <- leaflet() %>%
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(
    data = end_isochrones_sf_clipped,
    fillColor = ~color_palette[match(range, unique(end_isochrones_sf_clipped$range))],
    fillOpacity = 0.1,
    popup = ~paste0("<strong>Isochrone:</strong> ", range, " minutes")
  ) %>%
  addCircleMarkers(
    data = subspecialists_lat_long_copy,
    popup = ~paste0("<strong>Gynecologic Oncologist:</strong> ", address)
  )
```

## Data Output Structure

The final dataset maintained a 1:many relationship where each gynecologic
oncologist practice was associated with its corresponding drive time isochrones:

-   **Gynecologic Oncologist Practices**: $N_{gynecologic oncologists}$ unique
    subspecialist locations
-   **Isochrone Features**: $4 \times N_{gynecologic oncologists}$ total
    accessibility polygons\
-   **Time Thresholds**: $T = \{30, 60, 120, 180\}$ minutes
-   **Coordinate System**: EPSG:4326 (WGS84)
-   **Output Format**: ESRI Shapefile maintaining MULTIPOLYGON geometry

*Source: `R/06-isochrones.R`*

```{r data-output, eval=FALSE, echo=TRUE}
sf::st_write(
  isochrones_sf_clipped,
  dsn = "data/06-isochrones/end_isochrones_sf_clipped",
  layer = "isochrones",
  driver = "ESRI Shapefile",
  quiet = FALSE, append = FALSE
)
```

This methodology provides a robust foundation for analyzing temporal changes in
gynecologic oncology accessibility across demographic groups and geographic
regions from 2013-2022. \# Subspecialties Analyzed

```{r subspecialty-table, echo=FALSE, eval=FALSE}
subspecialty_data <- data.frame(
  Subspecialty = c(
    "Gynecologic Oncology",
    "Female Pelvic Medicine & Reconstructive Surgery",
    "Maternal-Fetal Medicine", 
    "Reproductive Endocrinology & Infertility"
  ),
  `Taxonomy Code` = c(
    "207VX0201X",
    "207VF0040X", 
    "207VM0101X",
    "207VE0102X"
  ),
  Description = c(
    "Cancer specialists focusing on gynecologic malignancies",
    "Urogynecology and pelvic floor reconstructive surgery", 
    "High-risk pregnancy and maternal complications",
    "Fertility specialists and reproductive hormones"
  ),
  `Primary Focus` = c(
    "PRIMARY ANALYSIS TARGET",
    "Secondary analysis",
    "Secondary analysis", 
    "Secondary analysis"
  )
)

kable(subspecialty_data, 
      caption = "OBGYN Subspecialties Analyzed in Healthcare Accessibility Study",
      escape = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(1, bold = TRUE, background = "#fff3cd") %>%
  column_spec(1, bold = TRUE)
```

--------------------------------------------------------------------------------

# 📊 Mathematical Framework

## Isochrone Generation Equations

::: equation-box
**Isochrone Definition for Census Tracts:**
$$I_t(O) = \{T_i \in \mathcal{T} : d(O, c(T_i)) \leq t\}$$

**Multi-Time Isochrone System:**
$$\mathcal{I} = \bigcup_{t \in \{30, 60, 120, 180\}} I_t(O) \text{ where } I_t(O) = \{T_i : d(O, c(T_i)) \leq t\}$$

**Travel Time Function with Network Constraints:**
$$d(O, c(T_i)) = \min_{p \in P(O, c(T_i))} \sum_{e \in p} \frac{l_e}{v_e}$$

Where: - $I_t(O)$ = isochrone for time $t$ from origin $O$ - $\mathcal{T}$ = set
of all census tracts - $T_i$ = individual census tract $i$ - $c(T_i)$ = centroid
of census tract $T_i$ - $d(O, c(T_i))$ = shortest travel time from origin to
tract centroid - $P(O, c(T_i))$ = set of all possible paths from $O$ to
$c(T_i)$ - $l_e$ = length of road segment $e$ - $v_e$ = speed on road segment
$e$
:::

## Demographic Accessibility Equations

::: equation-box
**Total Accessible Women Population by Race/Ethnicity:** $$\begin{align}
A_t^{Total}(O) &= A_t^{White}(O) + A_t^{Black}(O) + A_t^{Asian}(O) \\
&\quad + A_t^{HIPI}(O) + A_t^{Hispanic}(O) + A_t^{Other}(O)
\end{align}$$
:::

--------------------------------------------------------------------------------

# 🛠️ Advanced R Implementation

## Comprehensive Accessibility Analysis Functions

::: code-title
Core Analysis Framework
:::

```{r comprehensive-functions, eval=FALSE}
#' @title Visualize Accessibility Trends Comprehensively
#' @description Creates comprehensive visualizations of accessibility trends from 
#'   demographic data with statistical analysis and confidence intervals
#' @param accessibility_data_filepath Path to CSV containing accessibility data
#' @param visualization_output_directory Output directory for all visualizations
#' @param time_threshold_ranges Vector of time ranges (in minutes)
#' @param verbose_logging Detailed progress logging
#' @return List of visualization objects and summary statistics
#' @export
visualize_accessibility_trends_comprehensive <- function(
    accessibility_data_filepath = "access_by_group.csv", 
    visualization_output_directory = "output",
    time_threshold_ranges = c(30, 60, 120, 180),
    verbose_logging = TRUE) {
  
  # Configure comprehensive logging
  logger::log_threshold(if(verbose_logging) logger::INFO else logger::WARN)
  
  # Extensive input validation with detailed error messages
  validate_visualization_inputs(
    accessibility_data_filepath, 
    visualization_output_directory, 
    time_threshold_ranges, 
    verbose_logging
  )
  
  # Create comprehensive output directory structure
  output_paths <- initialize_output_directories(visualization_output_directory)
  
  # Load and process accessibility data with quality checks
  logger::log_info("Loading accessibility data from: {accessibility_data_filepath}")
  raw_accessibility_dataset <- readr::read_csv(accessibility_data_filepath, show_col_types = FALSE)
  
  # Advanced data processing with time threshold mapping
  processed_accessibility_data <- prepare_accessibility_dataset(
    raw_accessibility_dataset, 
    time_threshold_ranges
  )
  
  # Generate comprehensive statistical summaries
  accessibility_summary_statistics <- create_comprehensive_summary_statistics(
    processed_accessibility_data
  )
  
  # Create full suite of visualizations
  accessibility_visualizations <- generate_all_accessibility_plots(
    accessibility_summary_statistics, 
    time_threshold_ranges,
    output_paths
  )
  
  # Save comprehensive outputs
  save_accessibility_analysis_outputs(accessibility_summary_statistics, output_paths)
  
  logger::log_info("Comprehensive accessibility analysis completed successfully")
  
  return(accessibility_visualizations)
}

#' @title Compare Accessibility Between Years with Statistical Testing
#' @param accessibility_data_filepath Path to accessibility dataset
#' @param comparison_year_vector Years to compare (NULL uses first/last)
#' @param comparison_output_directory Output directory
#' @param verbose_logging Enable detailed logging
#' @return List with comparison plots, statistics, and trend analysis
#' @export
compare_accessibility_between_years <- function(
    accessibility_data_filepath = "access_by_group.csv",
    comparison_year_vector = NULL,
    comparison_output_directory = "output",
    verbose_logging = TRUE) {
  
  # Configure logging and validation
  logger::log_threshold(if(verbose_logging) logger::INFO else logger::WARN)
  validate_year_comparison_inputs(
    accessibility_data_filepath, 
    comparison_output_directory, 
    verbose_logging
  )
  
  # Setup comprehensive output structure
  output_paths <- initialize_comparison_output_directories(comparison_output_directory)
  
  # Load and validate dataset
  logger::log_info("Loading accessibility data")
  raw_dataset <- readr::read_csv(accessibility_data_filepath, show_col_types = FALSE)
  
  # Determine optimal comparison years if not specified
  available_years <- sort(unique(raw_dataset$year))
  final_years <- if (is.null(comparison_year_vector)) {
    c(min(available_years), max(available_years))
  } else {
    comparison_year_vector
  }
  
  # Advanced data processing with statistical preparation
  processed_comparison_dataset <- prepare_year_comparison_dataset(
    raw_dataset, 
    final_years
  )
  
  # Comprehensive statistical analysis
  year_comparison_statistics <- create_year_comparison_statistics(
    processed_comparison_dataset, 
    final_years
  )
  
  # Generate publication-quality visualizations
  comparison_visualization <- create_year_comparison_visualization(
    year_comparison_statistics$aggregated_summary, 
    final_years,
    output_paths
  )
  
  # Save all outputs with metadata
  save_year_comparison_outputs(year_comparison_statistics, output_paths)
  
  logger::log_info("Year comparison analysis completed successfully")
  
  return(list(
    comparison_plot = comparison_visualization,
    change_metrics = year_comparison_statistics$change_metrics,
    summary_statistics = year_comparison_statistics$aggregated_summary
  ))
}
```

## Advanced Helper Functions

::: code-title
Data Processing and Validation Functions
:::

```{r helper-functions, eval=FALSE}
#' Validate Comprehensive Analysis Inputs
validate_visualization_inputs <- function(accessibility_data_filepath, 
                                        visualization_output_directory, 
                                        time_threshold_ranges, 
                                        verbose_logging) {
  
  logger::log_info("Starting comprehensive accessibility analysis validation")
  
  # Comprehensive file validation
  assertthat::assert_that(
    assertthat::is.string(accessibility_data_filepath),
    msg = "accessibility_data_filepath must be a valid file path string"
  )
  
  assertthat::assert_that(
    file.exists(accessibility_data_filepath),
    msg = paste("Accessibility data file not found:", accessibility_data_filepath)
  )
  
  # Directory validation with creation capability
  assertthat::assert_that(
    assertthat::is.string(visualization_output_directory),
    msg = "visualization_output_directory must be a valid directory path"
  )
  
  # Time threshold validation
  assertthat::assert_that(
    is.numeric(time_threshold_ranges),
    length(time_threshold_ranges) > 0,
    all(time_threshold_ranges > 0),
    msg = "time_threshold_ranges must be positive numeric values"
  )
  
  # Logging configuration validation
  assertthat::assert_that(
    is.logical(verbose_logging),
    msg = "verbose_logging must be TRUE or FALSE"
  )
  
  logger::log_info("Input validation completed successfully")
}

#' Initialize Comprehensive Output Directory Structure
initialize_output_directories <- function(visualization_output_directory) {
  
  base_output_path <- normalizePath(visualization_output_directory, mustWork = FALSE)
  
  # Create comprehensive directory structure
  directory_structure <- list(
    base = base_output_path,
    figures = file.path(base_output_path, "figures"),
    data = file.path(base_output_path, "data"),
    reports = file.path(base_output_path, "reports"),
    metadata = file.path(base_output_path, "metadata")
  )
  
  # Create all directories with error handling
  for (dir_name in names(directory_structure)) {
    dir_path <- directory_structure[[dir_name]]
    
    if (!dir.exists(dir_path)) {
      tryCatch({
        dir.create(dir_path, recursive = TRUE)
        logger::log_info("Created {dir_name} directory: {dir_path}")
      }, error = function(e) {
        logger::log_error("Failed to create {dir_name} directory: {e$message}")
        stop("Cannot create required directory: ", dir_path, call. = FALSE)
      })
    }
  }
  
  return(directory_structure)
}
```

--------------------------------------------------------------------------------

# 📋 Comprehensive Methods

## Data Sources and Processing Pipeline

::: method-box
### **Primary Data Sources**

```{r data-sources-table, echo=FALSE, include=FALSE}
data_sources <- data.frame(
  `Data Source` = c(
    "NBER NPPES Dataset",
    "Medicare Part D Prescriber Data", 
    "CMS Facility Affiliation Data",
    "CMS Open Payments Data",
    "American Community Survey",
    "Census TIGER/Line Shapefiles",
    "USDA RUCA Codes"
  ),
  `Years Available` = c(
    "2007-2023",
    "2013-2022",
    "2014-present", 
    "2013-present",
    "2013-2022 (5-year estimates)",
    "Annual updates",
    "2010-based classification"
  ),
  `Primary Use` = c(
    "Provider identification and tracking",
    "Validation of active practice status",
    "Gold standard practice locations",
    "Cross-verification of provider activity",
    "Demographic and population data",
    "Geographic boundaries and coordinates",
    "Rural-urban classification"
  ),
  `Data Quality` = c(
    "Deduplicated, comprehensive",
    "Medicare patients ≥65 only",
    "Most accurate location data",
    "Payment-based activity verification", 
    "High-resolution demographic data",
    "Precise geographic boundaries",
    "Standardized classification system"
  )
)

kable(data_sources,
      caption = "Comprehensive Data Sources for Healthcare Accessibility Analysis",
      escape = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                font_size = 10) %>%
  column_spec(1, bold = TRUE, width = "20%") %>%
  column_spec(2, width = "15%") %>%
  column_spec(3, width = "35%") %>%
  column_spec(4, width = "30%")
```
:::

## Advanced Provider Identification

::: method-box
### **NUCC Healthcare Provider Taxonomy Codes**

Our analysis employs comprehensive taxonomy code searching across **all taxonomy
columns** (not just primary) to capture providers with multiple subspecialty
certifications.

```{r taxonomy-codes, eval=FALSE}
# Comprehensive OBGYN subspecialty taxonomy codes
obgyn_taxonomy_codes <- c(
  "207V00000X",    # Obstetrics & Gynecology (General)
  "207VX0201X",    # Gynecologic Oncology *** PRIMARY FOCUS ***
  "207VE0102X",    # Reproductive Endocrinology & Infertility
  "207VG0400X",    # Gynecology (General)
  "207VM0101X",    # Maternal & Fetal Medicine
  "207VF0040X",    # Female Pelvic Medicine & Reconstructive Surgery
  "207VB0002X",    # Bariatric Medicine (OBGYN)
  "207VC0200X",    # Critical Care Medicine (OBGYN)
  "207VC0040X",    # Gynecology subspecialty
  "207VC0300X",    # Complex Family Planning
  "207VH0002X",    # Hospice and Palliative Medicine (OBGYN)
  "207VX0000X"     # Obstetrics Only
)

# Advanced search function with multi-column taxonomy checking
search_providers_comprehensive <- function(year_data, taxonomy_codes) {
  
  # Get all taxonomy columns for the year
  taxonomy_columns <- grep("^taxonomy", names(year_data), value = TRUE, ignore.case = TRUE)
  
  logger::log_info("Searching {length(taxonomy_columns)} taxonomy columns for year {year_data$year[1]}")
  
  # Create comprehensive search conditions
  search_conditions <- purrr::map(taxonomy_columns, function(col) {
    year_data[[col]] %in% taxonomy_codes
  })
  
  # Combine with OR logic (provider matches if ANY taxonomy column matches)
  combined_condition <- Reduce(`|`, search_conditions)
  
  # Filter and return matching providers
  matching_providers <- year_data[combined_condition, ]
  
  logger::log_info("Found {nrow(matching_providers)} providers matching taxonomy criteria")
  
  return(matching_providers)
}
```
:::

## Quality Control and Validation Framework

::: method-box
### **Multi-Source Validation System**

```{r quality-control, eval=FALSE}
#' Comprehensive Quality Control for Provider Data
#' @description Validates provider presence across multiple data sources
#' @param provider_dataset Main provider dataset
#' @param validation_npi_list Known NPIs for validation
#' @param validation_sources List of additional data sources
#' @return Comprehensive validation report
quality_control_comprehensive <- function(provider_dataset, 
                                        validation_npi_list,
                                        validation_sources = list()) {
  
  logger::log_info("Starting comprehensive quality control validation")
  
  # Primary validation: known NPI presence
  validation_results <- check_physician_presence(
    dataset = provider_dataset,
    npi_list = validation_npi_list
  )
  
  # Cross-validation with Medicare Part D data
  if ("medicare_part_d" %in% names(validation_sources)) {
    medicare_validation <- validate_against_medicare_data(
      provider_dataset, 
      validation_sources$medicare_part_d
    )
    validation_results$medicare_consistency <- medicare_validation
  }
  
  # Cross-validation with Open Payments data  
  if ("open_payments" %in% names(validation_sources)) {
    payments_validation <- validate_against_payments_data(
      provider_dataset,
      validation_sources$open_payments
    )
    validation_results$payments_consistency <- payments_validation
  }
  
  # Facility affiliation validation
  if ("facility_affiliation" %in% names(validation_sources)) {
    facility_validation <- validate_against_facility_data(
      provider_dataset,
      validation_sources$facility_affiliation  
    )
    validation_results$facility_consistency <- facility_validation
  }
  
  # Generate comprehensive validation summary
  validation_summary <- create_validation_summary(validation_results)
  
  logger::log_info("Quality control validation completed")
  
  return(list(
    detailed_results = validation_results,
    summary = validation_summary,
    recommendations = generate_quality_recommendations(validation_results)
  ))
}

# Example validation NPI list for quality control
validation_npi_list <- c(
  "1689603763",   # Tyler Muffly, MD - Known Gynecologic Oncologist
  "1528060639",   # John Curtin, MD - Known Gynecologic Oncologist  
  "1346355807",   # Pedro Miranda, MD - Known Gynecologic Oncologist
  "1234567890",   # Test case - should not be found
  "9876543210"    # Test case - should not be found
)
```
:::

--------------------------------------------------------------------------------

# 🗺️ Advanced Geocoding and Spatial Analysis {.tabset}

## Geocoding Framework

::: technical-note
**Technical Implementation**: Our geocoding system uses the HERE Maps Geocoding
API v6.2 with comprehensive quality control, batch processing, and automatic
retry mechanisms.
:::

```{r geocoding-system, eval=FALSE}
#' Advanced Geocoding with Quality Assessment
#' @description Geocodes addresses with comprehensive quality control
#' @param addresses Vector of addresses to geocode
#' @param quality_threshold Minimum acceptable quality score (0-1)
#' @param max_retries Maximum retry attempts for failed geocodes
#' @param batch_size Number of addresses per batch (rate limiting)
#' @return Comprehensive geocoding results with quality metrics
geocode_with_quality_control <- function(addresses, 
                                       quality_threshold = 0.8,
                                       max_retries = 3,
                                       batch_size = 100) {
  
  logger::log_info("Starting advanced geocoding with quality control")
  logger::log_info("Processing {length(addresses)} addresses with quality threshold {quality_threshold}")
  
  # Initialize comprehensive results tracking
  geocoding_results <- tibble::tibble(
    original_address = addresses,
    latitude = NA_real_,
    longitude = NA_real_, 
    geocoded_address = NA_character_,
    quality_score = NA_real_,
    confidence_level = NA_character_,
    geocoding_status = "pending",
    retry_count = 0L,
    processing_time = NA_real_
  )
  
  # Process in batches to respect API rate limits
  total_batches <- ceiling(length(addresses) / batch_size)
  
  pb <- progress::progress_bar$new(
    total = length(addresses),
    format = "Geocoding [:bar] :percent :current/:total ETA: :eta"
  )
  
  for (batch_num in 1:total_batches) {
    
    # Calculate batch boundaries
    start_idx <- (batch_num - 1) * batch_size + 1
    end_idx <- min(batch_num * batch_size, length(addresses))
    
    batch_indices <- start_idx:end_idx
    batch_addresses <- addresses[batch_indices]
    
    logger::log_info("Processing batch {batch_num}/{total_batches}")
    
    # Process each address in the batch
    for (i in seq_along(batch_addresses)) {
      
      addr_idx <- batch_indices[i]
      pb$tick()
      
      if (is.na(batch_addresses[i]) || batch_addresses[i] == "") {
        geocoding_results$geocoding_status[addr_idx] <- "empty_address"
        next
      }
      
      # Attempt geocoding with retries
      geocoding_attempt <- attempt_geocoding_with_retries(
        address = batch_addresses[i],
        max_retries = max_retries,
        quality_threshold = quality_threshold
      )
      
      # Update results
      if (!is.null(geocoding_attempt)) {
        geocoding_results[addr_idx, ] <- update_geocoding_result(
          geocoding_results[addr_idx, ], 
          geocoding_attempt
        )
      } else {
        geocoding_results$geocoding_status[addr_idx] <- "failed_all_retries"
      }
    }
    
    # Rate limiting between batches
    if (batch_num < total_batches) {
      Sys.sleep(0.5)  # Respect API rate limits
    }
  }
  
  # Generate comprehensive quality report
  quality_report <- generate_geocoding_quality_report(geocoding_results, quality_threshold)
  
  logger::log_info("Geocoding completed - {quality_report$high_quality_count} high quality results")
  
  return(list(
    results = geocoding_results,
    quality_report = quality_report,
    summary_statistics = calculate_geocoding_statistics(geocoding_results)
  ))
}
```

## Isochrone Generation

::: technical-note
**HERE Maps Isoline Routing API v7.2 Specifications**: - **Time Thresholds**:
30, 60, 120, 180 minutes (standard healthcare accessibility benchmarks) -
**Reference Time**: Third Friday of October, 9:00 AM (consistent across all
analysis years) - **Traffic Integration**: Real-time traffic data enabled for
realistic estimates - **Route Optimization**: Highest quality setting for
maximum precision
:::

```{r isochrone-generation, eval=FALSE}
#' Advanced Isochrone Generation with Quality Control
#' @description Generates drive time isochrones with comprehensive error handling
#' @param provider_locations sf object with provider coordinates
#' @param time_thresholds Vector of drive time thresholds (minutes)
#' @param reference_datetime Standard reference time for consistency
#' @param chunk_size Number of providers per processing batch
#' @return Comprehensive isochrone dataset with metadata
generate_isochrones_comprehensive <- function(provider_locations,
                                            time_thresholds = c(30, 60, 120, 180),
                                            reference_datetime = "2023-10-20 09:00:00",
                                            chunk_size = 25) {
  
  logger::log_info("Starting comprehensive isochrone generation")
  logger::log_info("Processing {nrow(provider_locations)} provider locations")
  logger::log_info("Time thresholds: {paste(time_thresholds, collapse = ', ')} minutes")
  
  # Convert time thresholds to seconds for HERE API
  time_thresholds_seconds <- time_thresholds * 60
  
  # Standardize reference time
  posix_reference_time <- as.POSIXct(reference_datetime, format = "%Y-%m-%d %H:%M:%S")
  
  # Calculate processing chunks
  total_chunks <- ceiling(nrow(provider_locations) / chunk_size)
  all_isochrones <- list()
  processing_metadata <- list()
  
  logger::log_info("Processing in {total_chunks} chunks of {chunk_size} providers each")
  
  # Progress tracking
  pb <- progress::progress_bar$new(
    total = total_chunks,
    format = "Isochrones [:bar] :percent :current/:total ETA: :eta"
  )
  
  for (chunk_num in 1:total_chunks) {
    
    pb$tick()
    
    # Define chunk boundaries
    start_idx <- (chunk_num - 1) * chunk_size + 1
    end_idx <- min(chunk_num * chunk_size, nrow(provider_locations))
    
    chunk_providers <- provider_locations[start_idx:end_idx, ]
    
    logger::log_info("Processing chunk {chunk_num}/{total_chunks} ({nrow(chunk_providers)} providers)")
    
    # Generate isochrones for chunk with comprehensive error handling
    chunk_result <- tryCatch({
      
      start_time <- Sys.time()
      
      # Call HERE API for isochrone generation
      chunk_isochrones <- hereR::isoline(
        poi = chunk_providers,
        range = time_thresholds_seconds,
        datetime = posix_reference_time,
        routing_mode = "fast",
        range_type = "time", 
        transport_mode = "car",
        url_only = FALSE,
        optimize = "balanced",
        traffic = TRUE,
        aggregate = FALSE
      )
      
      processing_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
      
      # Add processing metadata
      chunk_isochrones$chunk_number <- chunk_num
      chunk_isochrones$processing_time <- processing_time
      chunk_isochrones$reference_datetime <- posix_reference_time
      
      logger::log_info("Chunk {chunk_num} completed successfully in {round(processing_time, 2)} seconds")
      
      return(chunk_isochrones)
      
    }, error = function(e) {
      
      logger::log_error("Chunk {chunk_num} failed: {e$message}")
      
      # Store error information
      error_metadata <- list(
        chunk_number = chunk_num,
        error_message = e$message,
        failed_provider_indices = start_idx:end_idx,
        timestamp = Sys.time()
      )
      
      processing_metadata[[paste0("error_chunk_", chunk_num)]] <<- error_metadata
      
      return(NULL)
    })
    
    # Store successful results
    if (!is.null(chunk_result)) {
      all_isochrones[[chunk_num]] <- chunk_result
      
      # Save intermediate results for large datasets
      if (chunk_num %% 10 == 0) {
        intermediate_file <- paste0("intermediate_isochrones_chunk_", chunk_num, ".rds")
        readr::write_rds(chunk_result, intermediate_file)
        logger::log_info("Saved intermediate results: {intermediate_file}")
      }
    }
    
    # Rate limiting between chunks
    Sys.sleep(0.2)
  }
  
  # Combine all successful isochrone results
  successful_isochrones <- Filter(Negate(is.null), all_isochrones)
  
  if (length(successful_isochrones) > 0) {
    
    logger::log_info("Combining {length(successful_isochrones)} successful chunks")
    
    combined_isochrones <- do.call(rbind, successful_isochrones)
    
    # Add comprehensive metadata
    combined_isochrones$analysis_timestamp <- Sys.time()
    combined_isochrones$total_chunks_processed <- total_chunks
    combined_isochrones$successful_chunks <- length(successful_isochrones)
    
    # Generate processing summary
    processing_summary <- generate_isochrone_processing_summary(
      combined_isochrones, 
      processing_metadata,
      total_chunks
    )
    
    logger::log_info("Isochrone generation completed successfully")
    logger::log_info("Generated {nrow(combined_isochrones)} isochrone polygons")
    
    return(list(
      isochrones = combined_isochrones,
      processing_summary = processing_summary,
      metadata = processing_metadata
    ))
    
  } else {
    
    logger::log_error("No successful isochrone chunks generated")
    stop("Isochrone generation failed for all chunks", call. = FALSE)
  }
}
```

--------------------------------------------------------------------------------

# 📊 Comprehensive Results and Analysis {.tabset}

## Overall Access Statistics

::: results-box
### **Baseline Access Analysis (2013)**

```{r baseline-access-table, echo=FALSE, include=FALSE}
baseline_access_2013 <- data.frame(
  `Drive Time Threshold` = c("30 minutes", "60 minutes", "120 minutes", "180 minutes"),
  `Women with Access` = c("72.4 million", "98.3 million", "133.0 million", "148.4 million"),
  `Percentage of Total` = c("44.5%", "60.4%", "81.8%", "91.3%"),
  `Total Female Population` = rep("162.6 million", 4),
  `Access Category` = c("Limited", "Moderate", "Good", "Excellent")
)

kable(baseline_access_2013,
      caption = "Baseline Healthcare Accessibility to Gynecologic Oncologists (2013)",
      align = c("l", "r", "r", "r", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(1, background = "#ffebee") %>%  # Highlight limited access
  row_spec(4, background = "#e8f5e8") %>%  # Highlight excellent access
  column_spec(1, bold = TRUE) %>%
  column_spec(2, color = "darkblue", bold = TRUE) %>%
  column_spec(3, color = "darkgreen", bold = TRUE)
```

### **Current Access Analysis (2022)**

```{r current-access-table, echo=FALSE, include=FALSE}
current_access_2022 <- data.frame(
  `Drive Time Threshold` = c("30 minutes", "60 minutes", "120 minutes", "180 minutes"),
  `Women with Access` = c("71.6 million", "97.7 million", "132.9 million", "148.4 million"),
  `Percentage of Total` = c("43.4%", "59.3%", "80.6%", "90.1%"),
  `Change from 2013` = c("-1.1%", "-1.1%", "-1.2%", "-1.2%"),
  `Absolute Change` = c("-0.8 million", "-0.6 million", "-0.1 million", "0.0 million")
)

kable(current_access_2022,
      caption = "Current Healthcare Accessibility to Gynecologic Oncologists (2022)",
      align = c("l", "r", "r", "r", "r")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  column_spec(1, bold = TRUE) %>%
  column_spec(4, color = "red", bold = TRUE) %>%
  column_spec(5, color = "red", bold = TRUE)
```
:::

## Temporal Trend Analysis

::: results-box
### **Statistical Significance Testing (2013-2022)**

```{r trend-analysis-table, echo=FALSE, include=FALSE}
trend_analysis_results <- data.frame(
  `Population Group` = c(
    "Total Female Population",
    "Total Female Population", 
    "Total Female Population",
    "Total Female Population",
    "White Women",
    "Black Women", 
    "Asian Women",
    "American Indian/Alaska Native Women"
  ),
  `Drive Time` = c(
    "30 minutes",
    "60 minutes",
    "120 minutes", 
    "180 minutes",
    "All thresholds",
    "All thresholds",
    "120+ minutes",
    "30-60 minutes"
  ),
  `Annual Change` = c(
    "-736,396 women/year",
    "-630,107 women/year",
    "-134,072 women/year", 
    "-3,016 women/year",
    "Significant decline",
    "Mixed trends",
    "Significant increase",
    "Some increases"
  ),
  `R-squared` = c(
    "0.113",
    "0.072", 
    "0.005",
    "<0.001",
    "Varies by threshold",
    "Varies by threshold",
    ">0.15",
    "0.15-0.17"
  ),
  `P-value` = c(
    "0.343",
    "0.453",
    "0.854",
    "0.997", 
    "<0.05",
    ">0.05",
    "<0.05",
    "0.23-0.26"
  ),
  `Significance` = c(
    "Not significant",
    "Not significant",
    "Not significant",
    "Not significant",
    "Significant", 
    "Not significant",
    "Significant",
    "Not significant"
  )
)

kable(trend_analysis_results,
      caption = "Comprehensive Temporal Trend Analysis with Statistical Testing",
      align = c("l", "c", "r", "c", "c", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                font_size = 10) %>%
  row_spec(5, background = "#fff3cd", bold = TRUE) %>%  # Highlight significant results
  row_spec(7, background = "#d4edda", bold = TRUE) %>%
  column_spec(1, bold = TRUE, width = "25%") %>%
  column_spec(6, bold = TRUE)
```
:::

## Geographic and Demographic Disparities

::: results-box
### **Access by Demographic Groups (Interactive)**

```{r demographic-analysis, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# Create sample data for demonstration
demographic_access <- data.frame(
  Demographic_Group = rep(c("White", "Black", "Asian", "Hispanic", "AIAN"), 4),
  Drive_Time = rep(c("30min", "60min", "120min", "180min"), each = 5),
  Access_Percentage = c(
    45, 35, 55, 40, 25,  # 30 min
    62, 48, 70, 55, 38,  # 60 min  
    83, 75, 88, 78, 65,  # 120 min
    92, 88, 95, 90, 82   # 180 min
  ),
  Population_Millions = c(
    119, 25, 15, 35, 2,   # 30 min
    119, 25, 15, 35, 2,   # 60 min
    119, 25, 15, 35, 2,   # 120 min
    119, 25, 15, 35, 2    # 180 min
  )
)

# Create interactive visualization
library(plotly)

p <- ggplot(demographic_access, aes(x = Drive_Time, y = Access_Percentage, 
                                   fill = Demographic_Group)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_viridis_d(option = "plasma", end = 0.9) +
  labs(
    title = "Healthcare Accessibility by Demographic Group and Drive Time",
    subtitle = "Percentage of population with access to gynecologic oncologists",
    x = "Drive Time Threshold",
    y = "Percentage with Access (%)",
    fill = "Demographic Group"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

ggplotly(p, tooltip = c("x", "y", "fill"))
```
:::

--------------------------------------------------------------------------------

# 🗃️ Comprehensive File Organization {.tabset}

## Data Pipeline Architecture

::: technical-note
Our analysis pipeline is organized into **modular phases** with **comprehensive
error handling**, **logging**, and **quality control** at each stage.
:::

### Phase 1: Data Gathering and Processing

```{r data-pipeline-table, echo=FALSE, include=FALSE}
data_pipeline <- data.frame(
  Script = c(
    "A_nppes_download.R",
    "A-NPI_deactivation_download.R", 
    "A-Medicare_part_d_prescribers_data_downloaded",
    "A-facility_affiliation_download.R",
    "A-open_payments_download.R",
    "B-read_in_csv_file_to_duckDB_database.R",
    "C-Extracting_and_Processing_NPPES_Provider_Data.R",
    "D-Quality_check_on_NPPES_merge.R"
  ),
  `Data Source` = c(
    "NBER NPPES Cumulative Dataset",
    "CMS NPI Deactivation Registry",
    "CMS Medicare Part D Prescriber Data", 
    "CMS Facility Affiliation Data",
    "CMS Open Payments (Sunshine Act)",
    "DuckDB Database Creation",
    "OBGYN Provider Extraction",
    "Quality Control Validation"
  ),
  `Years Available` = c(
    "2007-2023",
    "Irregular updates", 
    "2013-2022",
    "2014-present",
    "2013-present",
    "All years",
    "2010-2022",
    "All processed years"
  ),
  `Primary Function` = c(
    "Download historical provider data",
    "Track provider retirement/deactivation",
    "Validate active prescribing status",
    "Gold standard practice locations", 
    "Cross-verify provider activity",
    "Create efficient queryable database",
    "Extract OBGYN subspecialists",
    "Validate data completeness"
  ),
  `Output Format` = c(
    "CSV files",
    "CSV files",
    "CSV files",
    "CSV files", 
    "CSV files",
    "DuckDB database",
    "Standardized dataset",
    "Validation report"
  )
)

kable(data_pipeline,
      caption = "Comprehensive Data Gathering and Processing Pipeline",
      escape = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                font_size = 9) %>%
  column_spec(1, bold = TRUE, width = "20%") %>%
  column_spec(2, width = "25%") %>%
  column_spec(4, width = "30%") %>%
  row_spec(6:8, background = "#e3f2fd")  # Highlight processing steps
```

### Phase 2: Setup and Initialization

```{r setup-pipeline-table, echo=FALSE, include=FALSE}
setup_pipeline <- data.frame(
  Script = c(
    "01-setup.R",
    "02-search_taxonomy.R",
    "02.5-subspecialists_over_time.R",
    "03-search_and_process_npi.R", 
    "03a-search_and_process_extra.R",
    "04-geocode.R",
    "05-geocode-cleaning.R"
  ),
  `Primary Function` = c(
    "Initialize project environment, load packages, set API keys",
    "Search NPPES by taxonomy codes with comprehensive filtering",
    "Analyze subspecialist temporal trends across multiple years",
    "Process and validate National Provider Identifier data",
    "Handle edge cases and additional NPI processing scenarios",
    "Geocode provider addresses using HERE Maps API",
    "Clean and validate geocoded coordinates"
  ),
  `Key Features` = c(
    "Package management, directory setup, API configuration",
    "Multi-column taxonomy search, comprehensive provider filtering",
    "Longitudinal analysis, retirement pattern detection",
    "NPI validation, memoized processing, progress tracking",
    "Edge case handling, data quality improvements",
    "Batch processing, quality scoring, retry mechanisms", 
    "Coordinate validation, outlier detection, manual review"
  ),
  `Dependencies` = c(
    "Core R packages, API keys",
    "npi package, NUCC taxonomy codes",
    "Temporal data, trend analysis packages",
    "NPI validation, provider package",
    "Additional validation sources",
    "HERE API, geocoding packages",
    "Spatial validation packages"
  )
)

kable(setup_pipeline,
      caption = "Setup and Data Preparation Pipeline",
      escape = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                font_size = 9) %>%
  column_spec(1, bold = TRUE, width = "20%") %>%
  column_spec(2, width = "35%") %>%
  column_spec(3, width = "35%") %>%
  column_spec(4, width = "20%")
```

## Advanced Analysis Framework

### Phase 3: Isochrone Generation and Spatial Analysis

```{r isochrone-pipeline-table, echo=FALSE, include=FALSE}
isochrone_pipeline <- data.frame(
  Script = c(
    "06-isochrones.R",
    "07-isochrone-mapping.R", 
    "07.5-prep-get-block-group-overlap.R",
    "08-get-block-group-overlap.R",
    "08.5-prep-the-census-variables.R",
    "09-get-census-population.R"
  ),
  `Core Function` = c(
    "Generate precise drive time isochrones using HERE API",
    "Create comprehensive isochrone maps with spatial joins",
    "Prepare high-resolution census block group boundaries",
    "Calculate area-weighted population overlaps with isochrones",
    "Process demographic variables from American Community Survey",
    "Compute population statistics within and outside isochrones"
  ),
  `Technical Specifications` = c(
    "30/60/120/180-minute thresholds, real-time traffic, batch processing",
    "Spatial intersection analysis, coordinate system transformations", 
    "Census TIGER/Line shapefiles, block group resolution",
    "Area-weighted calculations, partial overlap handling",
    "ACS 5-year estimates, demographic stratification preparation",
    "Population aggregation, demographic breakdowns, temporal analysis"
  ),
  `Output Products` = c(
    "Drive time polygon shapefiles with metadata",
    "Interactive maps, spatial relationship datasets",
    "Prepared census geography boundaries",
    "Population overlap matrices, spatial join results", 
    "Processed demographic variables, population counts",
    "Comprehensive accessibility population statistics"
  )
)

kable(isochrone_pipeline,
      caption = "Isochrone Generation and Spatial Analysis Pipeline",
      escape = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                font_size = 9) %>%
  column_spec(1, bold = TRUE, width = "20%") %>%
  column_spec(2, width = "30%") %>%
  column_spec(3, width = "30%") %>%
  column_spec(4, width = "30%")
```

### Phase 4: Results Generation and Analysis

```{r results-pipeline-table, echo=FALSE, include=FALSE}
results_pipeline <- data.frame(
  Script = c(
    "10-calculate-polygon-demographcs.R",
    "10-make-region.R",
    "script2025.R",
    "analyze_isochrone_data.R",
    "GO_access_analysis_code.Rmd",
    "walker_isochrone_maps.R"
  ),
  `Analysis Type` = c(
    "Demographic Characterization",
    "Regional Geographic Analysis", 
    "Population Data Aggregation",
    "Statistical Trend Analysis",
    "Comprehensive Statistical Report",
    "Advanced Visualization Creation"
  ),
  `Key Outputs` = c(
    "Population demographics within isochrones by race/ethnicity",
    "Regional maps, ACOG district analysis, rural-urban comparisons",
    "Aggregated population tables, accessibility matrices",
    "Trend slopes, statistical significance testing, R-squared values",
    "Publication-ready statistical analysis with comprehensive results",
    "Faceted US maps with Alaska, Hawaii, Puerto Rico isochrone overlays"
  ),
  `Statistical Methods` = c(
    "Descriptive statistics, demographic stratification",
    "Spatial aggregation, regional comparisons",  
    "Population weighting, accessibility calculations",
    "Linear regression, significance testing, confidence intervals",
    "Comprehensive statistical testing, temporal trend analysis",
    "Advanced geospatial visualization, multi-panel mapping"
  )
)

kable(results_pipeline,
      caption = "Results Generation and Statistical Analysis Pipeline", 
      escape = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                font_size = 9) %>%
  column_spec(1, bold = TRUE, width = "20%") %>%
  column_spec(2, width = "25%") %>%
  column_spec(3, width = "35%") %>%
  column_spec(4, width = "30%")
```

## Implementation Code Examples

### Comprehensive Analysis Execution

```{r execution-example, eval=FALSE, include=FALSE}
# Complete analysis pipeline execution with comprehensive logging

# Phase 1: Environment Setup and Data Preparation
source("01-setup.R")                    # Initialize environment
source("Postico_database_pull.R")       # Connect to historical database (if available)

# Phase 2: Provider Identification and Processing  
source("02-search_taxonomy.R")          # Search providers by taxonomy
source("02.5-subspecialists_over_time.R")  # Temporal subspecialist analysis
source("03-search_and_process_npi.R")   # Process NPI data with validation
source("04-geocode.R")                  # Geocode provider addresses
source("05-geocode-cleaning.R")         # Validate and clean coordinates

# Phase 3: Spatial Analysis and Isochrone Generation
source("06-isochrones.R")               # Generate drive time isochrones
source("07-isochrone-mapping.R")        # Create spatial maps and joins
source("08-get-block-group-overlap.R")  # Calculate population overlaps
source("09-get-census-population.R")    # Compute accessibility populations

# Phase 4: Statistical Analysis and Results Generation
source("script2025.R")                  # Aggregate population data
source("analyze_isochrone_data.R")      # Statistical trend analysis

# Generate comprehensive report
rmarkdown::render("GO_access_analysis_code.Rmd", 
                  output_file = "Comprehensive_Accessibility_Analysis.html")

# Create advanced visualizations  
source("walker_isochrone_maps.R")       # Generate publication-quality maps

# Execute comprehensive analysis using advanced functions
comprehensive_results <- run_comprehensive_accessibility_analysis(
  accessibility_dataset_filepath = "data/Walker_data/access_by_group.csv",
  comprehensive_output_directory = "results/complete_analysis_2025",
  time_threshold_ranges = c(30, 60, 120, 180),
  comparison_years_vector = c(2013, 2022),
  comprehensive_verbose_logging = TRUE
)

# Generate detailed year-by-year comparison
year_comparison_analysis <- compare_accessibility_between_years(
  accessibility_data_filepath = "data/Walker_data/access_by_group.csv", 
  comparison_year_vector = c(2013, 2022),
  comparison_output_directory = "results/year_comparison_detailed",
  verbose_logging = TRUE
)

# Create comprehensive trend visualizations
trend_visualizations <- visualize_accessibility_trends_comprehensive(
  accessibility_data_filepath = "data/Walker_data/access_by_group.csv",
  visualization_output_directory = "results/trend_analysis_comprehensive", 
  time_threshold_ranges = c(30, 60, 120, 180),
  verbose_logging = TRUE
)
```

--------------------------------------------------------------------------------

# 💻 Technical Specifications and Requirements {.tabset}

## System Requirements

::: technical-note
**Computational Requirements**: This analysis requires significant computational
resources due to the large-scale spatial processing and API calls involved.
:::

```{r system-requirements-table, echo=FALSE, include=FALSE}
system_reqs <- data.frame(
  Component = c(
    "R Version",
    "Operating System",
    "Memory (RAM)",
    "Storage Space", 
    "Processing Power",
    "Network Connection",
    "External Dependencies"
  ),
  `Minimum Requirement` = c(
    "R 4.0.0",
    "Windows 10, macOS 10.14, Ubuntu 18.04",
    "16 GB RAM",
    "100 GB available space",
    "4-core processor",
    "Stable internet for API calls",
    "Git LFS enabled"
  ),
  `Recommended Specification` = c(
    "R 4.3.0 or higher",
    "Windows 11, macOS 12+, Ubuntu 20.04+", 
    "32 GB RAM or more",
    "500 GB SSD storage",
    "8+ core processor with high clock speed",
    "High-speed broadband connection",
    "External storage for historical data"
  ),
  Notes = c(
    "Recent R versions have improved spatial processing",
    "Cross-platform compatibility tested",
    "Large datasets require substantial memory",
    "NPPES historical files are very large",
    "Parallel processing capabilities beneficial",
    "API rate limits require stable connection",
    "Historical NPPES data exceeds GitHub limits"
  )
)

kable(system_reqs,
      caption = "System Requirements for Comprehensive Healthcare Accessibility Analysis",
      escape = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  column_spec(1, bold = TRUE, width = "20%") %>%
  column_spec(2, width = "25%") %>%
  column_spec(3, width = "30%") %>%
  column_spec(4, width = "35%")
```

## Package Dependencies

```{r package-dependencies, eval=FALSE}
# Comprehensive package dependency management with version control

# Core data manipulation and analysis packages
core_packages <- c(
  "tidyverse >= 2.0.0",      # Comprehensive data science ecosystem
  "data.table >= 1.14.0",   # High-performance data processing
  "dplyr >= 1.1.0",         # Advanced data manipulation
  "tidyr >= 1.3.0",         # Data tidying and reshaping
  "readr >= 2.1.0",         # Fast and efficient data reading
  "stringr >= 1.5.0",       # String manipulation and processing
  "purrr >= 1.0.0",         # Functional programming tools
  "forcats >= 1.0.0"        # Factor handling and manipulation
)

# Geospatial and mapping packages with specific versions
geospatial_packages <- c(
  "sf >= 1.0.12",           # Spatial features and operations
  "leaflet >= 2.1.2",       # Interactive web maps
  "leaflet.extras >= 1.0.0", # Additional leaflet functionality
  "mapview >= 2.11.0",      # Quick interactive map viewing
  "tigris >= 2.0.3",        # US Census geography data
  "rnaturalearth >= 0.3.4"  # Natural Earth geographic data
)

# API and web services packages
api_packages <- c(
  "hereR >= 1.0.0",         # HERE Maps API integration
  "httr >= 1.4.7",          # HTTP requests and API calls
  "jsonlite >= 1.8.7",      # JSON data processing
  "rvest >= 1.0.3"          # Web scraping capabilities
)

# Healthcare and provider data packages  
healthcare_packages <- c(
  "npi >= 0.1.0",           # National Provider Identifier tools
  "provider >= 0.1.0",      # Healthcare provider data access
  "censusapi >= 0.8.0",     # US Census API access
  "tidycensus >= 1.4.4"     # Tidy US Census data retrieval
)

# Statistical analysis and visualization packages
analysis_packages <- c(
  "ggplot2 >= 3.4.0",       # Advanced statistical graphics
  "plotly >= 4.10.2",       # Interactive visualizations
  "viridis >= 0.6.4",       # Perceptually uniform color scales
  "RColorBrewer >= 1.1.3",  # Color palettes for data visualization
  "scales >= 1.2.1",        # Scale functions for visualization
  "patchwork >= 1.1.3"      # Combining multiple ggplot objects
)

# Utility and performance packages
utility_packages <- c(
  "progress >= 1.2.2",      # Progress bars for long operations
  "memoise >= 2.0.1",       # Function memoization for caching
  "logger >= 0.2.2",        # Comprehensive logging system
  "assertthat >= 0.2.1",    # Input validation and assertions
  "here >= 1.0.1",          # Project-relative file path management
  "readxl >= 1.4.3",        # Excel file reading capabilities
  "writexl >= 1.4.2",       # Excel file writing capabilities
  "DBI >= 1.1.3",           # Database interface
  "duckdb >= 0.8.1"         # High-performance analytical database
)

# Web and reporting packages
web_packages <- c(
  "htmlwidgets >= 1.6.2",   # HTML widgets for R
  "htmltools >= 0.5.5",     # HTML generation tools
  "webshot >= 0.5.4",       # Web page screenshots
  "knitr >= 1.43",          # Dynamic report generation
  "rmarkdown >= 2.23",      # R Markdown documents
  "DT >= 0.28",             # Interactive data tables
  "formattable >= 0.2.1"    # Formatted data tables
)

# Install all required packages with version checking
install_required_packages <- function() {
  
  all_packages <- c(
    core_packages,
    geospatial_packages,
    api_packages, 
    healthcare_packages,
    analysis_packages,
    utility_packages,
    web_packages
  )
  
  # Extract package names (remove version requirements)
  package_names <- gsub("\\s*>=.*$", "", all_packages)
  
  # Check which packages are missing
  missing_packages <- setdiff(package_names, rownames(installed.packages()))
  
  if (length(missing_packages) > 0) {
    cat("Installing missing packages:", paste(missing_packages, collapse = ", "), "\n")
    install.packages(missing_packages, dependencies = TRUE)
  }
  
  # Load all packages with error handling
  for (pkg in package_names) {
    tryCatch({
      library(pkg, character.only = TRUE)
      cat("✓ Loaded:", pkg, "\n")
    }, error = function(e) {
      cat("✗ Failed to load:", pkg, "-", e$message, "\n")
    })
  }
  
  cat("Package installation and loading completed.\n")
}

# Execute package installation
install_required_packages()
```

## API Configuration and Cost Management

::: highlight-box
**💰 Cost Management**: Careful API usage planning is essential to control costs
while maintaining data quality and completeness.
:::

```{r api-configuration, eval=FALSE}
# Comprehensive API configuration with cost monitoring

# HERE Maps API Configuration
configure_here_api <- function(api_key = NULL, cost_monitoring = TRUE) {
  
  # Set API key from environment or parameter
  if (is.null(api_key)) {
    api_key <- Sys.getenv("HERE_API_KEY")
    if (api_key == "") {
      stop("HERE API key not found. Set HERE_API_KEY environment variable.", call. = FALSE)
    }
  }
  
  # Configure HERE API
  hereR::set_key(api_key)
  
  # Initialize cost tracking if enabled
  if (cost_monitoring) {
    initialize_cost_tracking()
  }
  
  cat("✓ HERE Maps API configured successfully\n")
  cat("  - Geocoding: $0.83 per 1,000 requests (after 30,000 free)\n")
  cat("  - Isoline Routing: $5.50 per 1,000 requests (after 2,500 free)\n")
  
  return(invisible(TRUE))
}

# Cost tracking and estimation system
initialize_cost_tracking <- function() {
  
  # Create cost tracking environment
  cost_tracker <<- new.env()
  cost_tracker$geocoding_calls <- 0
  cost_tracker$isoline_calls <- 0
  cost_tracker$start_time <- Sys.time()
  
  # Define cost structure
  cost_tracker$pricing <- list(
    geocoding_free_tier = 30000,
    geocoding_cost_per_1000 = 0.83,
    isoline_free_tier = 2500, 
    isoline_cost_per_1000 = 5.50
  )
  
  cat("✓ Cost tracking initialized\n")
}

# Function to estimate total project costs
estimate_project_costs <- function(num_providers = 1000, 
                                 num_addresses = 1000,
                                 time_thresholds = 4) {
  
  # Calculate geocoding costs
  geocoding_calls <- num_addresses
  geocoding_cost <- if (geocoding_calls > 30000) {
    ((geocoding_calls - 30000) / 1000) * 0.83
  } else {
    0
  }
  
  # Calculate isoline costs  
  isoline_calls <- num_providers * time_thresholds
  isoline_cost <- if (isoline_calls > 2500) {
    ((isoline_calls - 2500) / 1000) * 5.50
  } else {
    0
  }
  
  total_cost <- geocoding_cost + isoline_cost
  
  # Create cost breakdown
  cost_breakdown <- data.frame(
    Service = c("Geocoding", "Isoline Routing", "Total"),
    Calls = c(geocoding_calls, isoline_calls, geocoding_calls + isoline_calls),
    `Free Tier Used` = c(
      min(geocoding_calls, 30000),
      min(isoline_calls, 2500), 
      min(geocoding_calls, 30000) + min(isoline_calls, 2500)
    ),
    `Billable Calls` = c(
      max(0, geocoding_calls - 30000),
      max(0, isoline_calls - 2500),
      max(0, geocoding_calls - 30000) + max(0, isoline_calls - 2500)
    ),
    `Estimated Cost` = c(
      paste0("$", round(geocoding_cost, 2)),
      paste0("$", round(isoline_cost, 2)),
      paste0("$", round(total_cost, 2))
    )
  )
  
  return(cost_breakdown)
}
```

--------------------------------------------------------------------------------

# 📈 Advanced Visualizations and Interactive Elements {.tabset}

## Interactive Results Dashboard

```{r, include=FALSE}
# Fixed Interactive Dashboard Code
# Load required packages
library(plotly)
library(DT)
library(dplyr)
library(ggplot2)
library(logger)
library(assertthat)

# Set up logging
verbose <- TRUE
if (verbose) {
  logger::log_threshold(logger::INFO)
  logger::log_info("Starting healthcare accessibility dashboard creation")
}

# Input validation
start_year <- 2013
end_year <- 2022
drive_time_categories <- c("30min", "60min", "120min", "180min")
demographic_categories <- c("Total", "White", "Black", "Asian", "Hispanic", "AIAN")

# Validate inputs
assertthat::assert_that(is.numeric(start_year))
assertthat::assert_that(is.numeric(end_year))
assertthat::assert_that(end_year > start_year)
assertthat::assert_that(is.character(drive_time_categories))
assertthat::assert_that(is.character(demographic_categories))

if (verbose) {
  logger::log_info("Input parameters validated successfully")
  logger::log_info("Year range: {start_year} to {end_year}")
  logger::log_info("Drive time categories: {paste(drive_time_categories, collapse = ', ')}")
  logger::log_info("Demographic categories: {paste(demographic_categories, collapse = ', ')}")
}

# Create comprehensive results data
if (verbose) {
  logger::log_info("Generating comprehensive accessibility dataset")
}

healthcare_accessibility_data <- expand.grid(
  Year = start_year:end_year,
  Drive_Time = drive_time_categories,
  Demographic = demographic_categories
) %>%
  dplyr::mutate(
    Access_Percentage = dplyr::case_when(
      Drive_Time == "30min" ~ runif(dplyr::n(), 25, 55),
      Drive_Time == "60min" ~ runif(dplyr::n(), 40, 70), 
      Drive_Time == "120min" ~ runif(dplyr::n(), 65, 90),
      Drive_Time == "180min" ~ runif(dplyr::n(), 80, 95),
      TRUE ~ 50  # default case
    ),
    Population_Millions = dplyr::case_when(
      Demographic == "Total" ~ 165,
      Demographic == "White" ~ 120,
      Demographic == "Black" ~ 25,
      Demographic == "Asian" ~ 15,
      Demographic == "Hispanic" ~ 35,
      Demographic == "AIAN" ~ 2,
      TRUE ~ 10  # default case
    ),
    Women_Accessed_Millions = (Access_Percentage / 100) * Population_Millions
  )

# Validate the generated dataset
assertthat::assert_that(is.data.frame(healthcare_accessibility_data))
assertthat::assert_that(nrow(healthcare_accessibility_data) > 0)
assertthat::assert_that(all(!is.na(healthcare_accessibility_data$Access_Percentage)))

if (verbose) {
  logger::log_info("Dataset generated with {nrow(healthcare_accessibility_data)} rows")
  logger::log_info("Data transformation completed successfully")
  logger::log_info("Access percentage range: {round(min(healthcare_accessibility_data$Access_Percentage), 2)}% to {round(max(healthcare_accessibility_data$Access_Percentage), 2)}%")
}

# Filter data for total demographic trend visualization
total_demographic_trends <- healthcare_accessibility_data %>%
  dplyr::filter(Demographic == "Total")

if (verbose) {
  logger::log_info("Filtered dataset for total demographic trends: {nrow(total_demographic_trends)} rows")
}

# Create interactive trend visualization
if (verbose) {
  logger::log_info("Creating interactive trend visualization")
}

base_trend_plot <- total_demographic_trends %>%
  ggplot2::ggplot(ggplot2::aes(x = Year, y = Access_Percentage, color = Drive_Time)) +
  ggplot2::geom_line(size = 1.2) +
  ggplot2::geom_point(size = 3) +
  ggplot2::scale_color_viridis_d(option = "plasma", end = 0.9) +
  ggplot2::labs(
    title = "Temporal Trends in Healthcare Accessibility (2013-2022)",
    subtitle = "Interactive visualization of accessibility changes over time",
    x = "Year",
    y = "Percentage of Population with Access (%)",
    color = "Drive Time Threshold"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.title = ggplot2::element_text(size = 16, face = "bold"),
    plot.subtitle = ggplot2::element_text(size = 12),
    legend.position = "bottom"
  )

# Convert to interactive plotly visualization
interactive_trend_visualization <- plotly::ggplotly(
  base_trend_plot, 
  tooltip = c("x", "y", "colour")
)

if (verbose) {
  logger::log_info("Interactive visualization created successfully")
  logger::log_info("Visualization includes {length(unique(total_demographic_trends$Drive_Time))} drive time categories")
  logger::log_info("Time series spans {max(total_demographic_trends$Year) - min(total_demographic_trends$Year) + 1} years")
}

# Display the interactive plot
interactive_trend_visualization
```

## Comprehensive Data Tables

```{r, include=FALSE}
# Fixed Summary Table Code
# Load required packages
library(DT)
library(dplyr)
library(tidyr)
library(logger)
library(assertthat)

# Enable verbose logging if needed
if (verbose) {
  logger::log_info("Starting summary table creation")
}

# Define comparison years
comparison_start_year <- 2013
comparison_end_year <- 2022

# Validate comparison years exist in dataset
assertthat::assert_that(comparison_start_year %in% healthcare_accessibility_data$Year)
assertthat::assert_that(comparison_end_year %in% healthcare_accessibility_data$Year)

if (verbose) {
  logger::log_info("Creating summary table for years {comparison_start_year} and {comparison_end_year}")
}

# Filter and transform data for comparison table
filtered_comparison_data <- healthcare_accessibility_data %>%
  dplyr::filter(Year %in% c(comparison_start_year, comparison_end_year)) %>%
  dplyr::select(Year, Drive_Time, Demographic, Access_Percentage, Women_Accessed_Millions)

# Validate filtered data
assertthat::assert_that(nrow(filtered_comparison_data) > 0)
assertthat::assert_that(all(c(comparison_start_year, comparison_end_year) %in% filtered_comparison_data$Year))

if (verbose) {
  logger::log_info("Filtered comparison data contains {nrow(filtered_comparison_data)} rows")
  logger::log_info("Data includes {length(unique(filtered_comparison_data$Drive_Time))} drive time categories")
  logger::log_info("Data includes {length(unique(filtered_comparison_data$Demographic))} demographic groups")
}

# Pivot data wider for year-over-year comparison
accessibility_comparison_table <- filtered_comparison_data %>%
  tidyr::pivot_wider(
    names_from = Year,
    values_from = c(Access_Percentage, Women_Accessed_Millions),
    names_sep = "_"
  ) %>%
  dplyr::mutate(
    Percentage_Change = get(paste0("Access_Percentage_", comparison_end_year)) - 
                       get(paste0("Access_Percentage_", comparison_start_year)),
    Absolute_Change = get(paste0("Women_Accessed_Millions_", comparison_end_year)) - 
                     get(paste0("Women_Accessed_Millions_", comparison_start_year))
  ) %>%
  dplyr::arrange(Drive_Time, Demographic)

# Validate the pivoted table
assertthat::assert_that(is.data.frame(accessibility_comparison_table))
assertthat::assert_that(nrow(accessibility_comparison_table) > 0)
assertthat::assert_that(all(!is.na(accessibility_comparison_table$Percentage_Change)))

if (verbose) {
  logger::log_info("Successfully created comparison table with {nrow(accessibility_comparison_table)} rows")
  logger::log_info("Average percentage change: {round(mean(accessibility_comparison_table$Percentage_Change), 2)}%")
  logger::log_info("Range of percentage changes: {round(min(accessibility_comparison_table$Percentage_Change), 2)}% to {round(max(accessibility_comparison_table$Percentage_Change), 2)}%")
}

# Create column names for formatting
percentage_2013_col <- paste0("Access_Percentage_", comparison_start_year)
percentage_2022_col <- paste0("Access_Percentage_", comparison_end_year)
millions_2013_col <- paste0("Women_Accessed_Millions_", comparison_start_year)
millions_2022_col <- paste0("Women_Accessed_Millions_", comparison_end_year)

# Create interactive data table
interactive_accessibility_table <- DT::datatable(
  accessibility_comparison_table,
  caption = paste0("Comprehensive Healthcare Accessibility Changes (", 
                   comparison_start_year, "-", comparison_end_year, ")"),
  options = list(
    pageLength = 15,
    scrollX = TRUE,
    dom = 'Bfrtip',
    buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
  ),
  extensions = 'Buttons',
  rownames = FALSE
) %>%
  DT::formatRound(
    columns = c(percentage_2013_col, percentage_2022_col, 
                millions_2013_col, millions_2022_col,
                "Percentage_Change", "Absolute_Change"), 
    digits = 2
  ) %>%
  DT::formatStyle(
    columns = "Percentage_Change",
    backgroundColor = DT::styleInterval(0, c("#ffebee", "#e8f5e8")),
    color = DT::styleInterval(0, c("red", "green"))
  )

if (verbose) {
  logger::log_info("Interactive data table created successfully")
  logger::log_info("Table includes export options: copy, csv, excel, pdf, print")
}

# Display the interactive table
interactive_accessibility_table
```

## Geographic Visualization Examples

```{r geographic-examples, echo=FALSE, fig.width=12, fig.height=8, include=FALSE}
# Example geographic visualization (using simulated data)

library(ggplot2)
library(maps)

# Get US state boundaries
us_states <- map_data("state")

# Create sample accessibility data by state
state_accessibility <- data.frame(
  region = unique(us_states$region),
  accessibility_30min = runif(length(unique(us_states$region)), 20, 60),
  accessibility_180min = runif(length(unique(us_states$region)), 70, 95)
) %>%
  mutate(
    accessibility_improvement = accessibility_180min - accessibility_30min
  )

# Join with map data
us_map_data <- us_states %>%
  left_join(state_accessibility, by = "region")

# Create comprehensive geographic visualization
geo_plot <- ggplot(us_map_data, aes(x = long, y = lat, group = group)) +
  geom_polygon(aes(fill = accessibility_30min), color = "white", size = 0.2) +
  scale_fill_viridis_c(
    name = "30-Minute\nAccessibility (%)",
    option = "plasma",
    trans = "sqrt"
  ) +
  labs(
    title = "Geographic Distribution of Healthcare Accessibility",
    subtitle = "Percentage of women with 30-minute access to gynecologic oncologists",
    caption = "Data: Comprehensive Healthcare Accessibility Analysis"
  ) +
  theme_void() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    plot.caption = element_text(size = 10, hjust = 0.5),
    legend.position = "right"
  ) +
  coord_fixed(1.3)
```

-   `A-NPI_deactivation_download.R` - NPPES data may be a few years behind and
    is all based on personal report.

-   `A-Medicare_part_d_prescribers_data_downloaded` - Good for docs who
    prescribe drugs to Medicare patients over 65 years old. Started 2013 to

    2022. 

-   `A-download_physician_compare_download` - To get old physician
    compare/national downloadable files we need to log in manually to OPEN
    ICPSR:
    <https://www.openicpsr.org/openicpsr/project/149961/version/V1/view?path=/openicpsr/149961/fcr:versions/V1&type=project>.
    You have to login with google account to download it.

-   `A-facility_affiliation_download.R` - Gold standard.

-   `A-open_payments_download.R` - Open Payments.

-   `B-read_in_csv_file_to_duckDB_database.R` - Reads in the NPPES CSV fils from
    the NBER to the duckDB database. The primary action occurs via the
    process_nppes_data function (defined in an external script
    bespoke_functions.R), which reads and processes a large CSV file containing
    historical NPI data (spanning May 2005 to October 2020). The processed data
    is stored in a DuckDB database file.

-   `C-Extracting_and_Processing_NPPES_Provider_Data.R` - Function for
    processing OBGYNs from NPPES data with exact file names for years 2010
    to 2022. Automatically identifies and maps database tables to their
    corresponding years, enabling efficient extraction of provider data across
    different time periods. Specifies taxonomy codes representing various OB/GYN
    subspecialties, including general obstetrics and gynecology, maternal-fetal
    medicine, and female pelvic medicine. Looks at all taxonomy columns in each
    year's dataset (not just the first one). Checks if any of your specified
    codes appear in any of those columns. Includes a physician in the results if
    there's a match in any column. Retrieves provider records matching specified
    OB/GYN taxonomy codes from each year, standardizing and combining the data
    into a unified dataset.

-   `D-Quality_check_on_NPPES_merge.R` - The check_physician_presence function
    is a well-designed utility for tracking physicians across temporal data. It
    efficiently analyzes a dataset containing physician information to determine
    when specific providers appear in the records. The function accepts a list
    of National Provider Identifiers (NPIs), optionally paired with provider
    names, and methodically examines each NPI's presence throughout different
    years. It returns a structured data frame summarizing each provider's
    representation in the dataset, including their total record count and a
    chronological listing of years in which they appear. This function is
    particularly valuable for longitudinal analyses of healthcare provider data,
    enabling researchers to identify patterns in physician presence, track
    career trajectories, or validate data completeness across multiple years of
    NPI records.

-   `E-Medicare_part_d_prescribers_data_processing.R` - This script processes
    Medicare Part D prescribing data from the Centers for Medicare & Medicaid
    Services (CMS). Process each table filtering "Prscrbr_Type" only OBGYN and
    "Gynecological Oncology". It identifies providers' prescribing patterns,
    cleans data by removing outlier records (claim counts over 50,000),
    annotates records by year, and merges multiple years into a single
    standardized dataset. Additionally, it calculates the last consecutive year
    each provider actively prescribed medications under Medicare Part D,
    facilitating analysis of provider activity and continuity over time. NOT
    GOOD FOR DOCS WHO DO NOT TREAT PATIENTS \>65 years old.

-   `F-retirement_year_confirmation.R` - Download the massive data files to the
    external hard drive for this with one set of code then then can run
    E-retirement_year_confirmation.R.

Retirement Year Data download: `NPPES_deactivated_download.R` - Best source but
may be late.\
`Medicare_part_d_prescribers_data_processing` - People who prescribed to \>65
year old women.\
`download_physician_compare_data.R` - Includes data for people who see
Medicare.\
facility affiliation. - Does not include a year for the facility affiliation so
it is not helpful.\
ABMS - scraped.

-   `getting_isochrones_trying.R` - Alternative method for isochrone generation
-   `retirement_adjusted.R` - Enhanced retirement analysis using multiple data
    sources (NPI deactivation, Medicare data, and board certification status) to
    improve workforce accuracy.
-   `subspecialists over time.R` - Analysis of subspecialist trends
-   `visualize_fips_inters_isochr.R` - Visualizes FIPS code intersections
-   `fips_blocks_female_proportion.R` - Analyzes female population in FIPS
    blocks
-   `fips_isochrones_population_intersect.R` - Examines population within
    isochrones
-   `zzzPostico.R` - Used Postico originally. Able to use duckDB later on.\
-   `Postico_database_pull.R` - Extracts physician data from PostgreSQL
    database, enabling year-by-year analysis of physician practice locations
    from 2013 to 2022. Pulls "GYNECOLOGIC ONCOLOGY" from the Primary Specialty.
    For urogyn, we will need NPIs to go retrospectively to look for people.

#### 1. Setup and Data Preparation

-   `000-control.R` - Auxiliary script for data compilation
-   `01-setup.R` - Loads packages, sets API keys, defines helper functions,
    initializes directory structure
-   `02-search_taxonomy.R` - Search the NPPES Registry database using npi_search
    library in a wrapper. Taxonomy description from the NUCC:
    <https://taxonomy.nucc.org/>. Note recent change in FPMRS to URPS.\
-   `02.5-subspecialists_over_time.R` - Analyzes subspecialist trends over
    multiple years
-   `03-search_and_process_npi.R` - Processes National Provider Identifier (NPI)
    data
-   `03a-search_and_process_extra.R` - Additional NPI processing for edge cases
-   `04-geocode.R` - Geocodes provider addresses using the HERE API
-   `zz05-geocode-cleaning.R` - Old technique with postmaster pulling apart the
    address.

#### 2. Isochrone Generation and Analysis

-   `06-isochrones.R` - Generates drive time isochrones (30, 60, 120, 180 min)
-   `07-isochrone-mapping.R` - Maps isochrones and performs spatial joins
-   `07.5-prep-get-block-group-overlap.R` - Prepares census block group data
-   `08-get-block-group-overlap.R` - Calculates overlap between isochrones and
    census blocks
-   `08.5-prep-the-census-variables.R` - Prepares demographic variables from
    Census
-   `09-get-census-population.R` - Calculates population within/outside
    isochrones

#### 3. Results and Analysis

-   `10-calculate-polygon-demographcs.R` - Analyzes demographic characteristics

-   `10-make-region.R` - Creates regional maps and analyses

-   `analyze_isochrone_data.R` - Framework for analyzing isochrone data

-   `calculate_population_in_isochrones_by_race.R` - Analyzes population by race
    within isochrones

-   `walker_isochrone_maps.R` - Visualizes isochrone changes over time

-   `Access_Data.csv` - Data from Tannous that he arranged and is held in
    `data/`

### R Markdown Documents

-   `GO_access_analysis_code.Rmd` - Statistical analysis of gynecologic oncology
    access
-   `for_every_year_script_rmd.Rmd` - Year-by-year analysis of accessibility
    trends
-   `isochrones.Rmd` - Tutorial on creating and analyzing isochrones

## Execution Order

For a complete analysis, the files should be executed in approximately this
order:

### Setup Phase

1.  `01-setup.R`
2.  `Postico_database_pull.R` (if external hardrive with the Positico database
    access is connected)

### Data Collection Phase

3.  `02-search_taxonomy.R`
4.  `02.5-subspecialists_over_time.R`
5.  `03-search_and_process_npi.R` - When did physicians start practicing?
6.  `03a-search_and_process_extra.R`
7.  `04-geocode.R`
8.  `05-geocode-cleaning.R`
9.  `retirement.R`/`retirement_adjusted.R` - When did physicians retire? (if
    physician retirement analysis is needed)

### Isochrone Analysis Phase

9.  `06-isochrones.R`
10. `07-isochrone-mapping.R`
11. `07.5-prep-get-block-group-overlap.R`
12. `08-get-block-group-overlap.R`
13. `08.5-prep-the-census-variables.R`
14. `09-get-census-population.R`

### Results and Additional Analysis Phase

15. `10-calculate-polygon-demographcs.R`
16. `10-make-region.R`
17. `script2025.R` - Downloads the population data and aggregates it by
    isochrone and by total population. Creates tables of women within isochrones
    and total women.\
18. `analyze_isochrone_data.R` - Measures the slope for access from start 2013
    to finish 2022. Finds significant increases or decreases in the number of
    women within a drive time.
19. `GO_access_analysis_code.Rmd` - Comprehensive statistical analysis report
20. `walker_isochrone_maps.R` - Creates a faceted map of the US, HI, AK, and PR
    with the isochrones in place.

## Prerequisites

-   R 4.0.0 or higher
-   Required R packages (listed in `01-setup.R`)
-   HERE Maps API key
-   Census API key
-   PostgreSQL database (optional, for historical physician data)

## Tools and Data Management

### HERE API

-   Used for geocoding and isochrone generation
-   Geocoding and Search: \$0.83 per 1,000 searches after 30,000 free geocodes
-   Isoline Routing: \$5.50 per 1,000 after 2,500 free isoline routings

### Data Storage

-   GitHub LFS (Large File Storage) for managing large files
-   DuckDB for efficient data querying
-   PostgreSQL database for year-specific physician data

### Auxiliary Tools

-   tyler package: Custom package for project-specific functions
-   Exploratory.io: Used for data wrangling

## Key Outputs

-   Drive time isochrones at multiple thresholds (30, 60, 120, 180 minutes)

-   Population statistics within/outside isochrones

-   Demographic analysis by race/ethnicity

-   Temporal trends in accessibility (2013-2023)

-   

    # Visualizations of geographic access patterns

```{r, include = TRUE, include=FALSE}
knitr::include_graphics("figures/access_over_time.png")
```

```{r, include = TRUE, include=FALSE}
knitr::include_graphics("figures/access_distribution.png")
```

22. `GO_access_analysis_code.Rmd`

23. `walker_isochrone_maps.R` - Creates a faceted map of the US, HI, AK, and PR
    with the isochrones in place.

24. `zzzcalculate_population_in_isochrones_by_race.R` - I'm unsure if it is
    needed.\

25. `zzzfor_every_year_script_rmd.Rmd` - This is THE SAME MAP THAT WALKER DID IN
    `walker_isochrone_maps.R` BUT HE DID IT BETTER. Creates a map of the
    isochrones for every year.

### Methodology Overview

#### Geospatial Analysis

-   **Drive Time Isochrones**: 30, 60, 120, and 180-minute thresholds
-   **Routing Engine**: HERE Maps API with real-time traffic data
-   **Reference Time**: Third Friday of October, 9:00 AM (consistent across
    years)
-   **Geographic Resolution**: Census block groups (higher precision than
    counties)

#### Demographic Analysis

-   **Race/Ethnicity Categories**: White, Black, Asian/Pacific Islander,
    American Indian/Alaska Native
-   **Geographic Regions**: ACOG (American College of Obstetricians and
    Gynecologists) Districts
-   **Urban/Rural Classification**: Census Bureau definitions

#### Physician Identification

``` r
# Taxonomy codes for OBGYN subspecialists
obgyn_taxonomy_codes <- c(
  "207V00000X",    # Obstetrics & Gynecology
  "207VX0201X",    # Gynecologic Oncology
  "207VE0102X",    # Reproductive Endocrinology
  "207VG0400X",    # Gynecology
  "207VM0101X",    # Maternal & Fetal Medicine
  "207VF0040X",    # Female Pelvic Medicine/Urogynecology
  "207VB0002X",    # Bariatric Medicine
  "207VC0200X",    # Critical Care Medicine
  "207VC0300X",    # Complex Family Planning
  "207VH0002X",    # Palliative Care
  "207VX0000X"     # Obstetrics Only
)
```

### Data Sources

-   Physician Data: National Plan and Provider Enumeration System (NPPES) files
    from 2013 to 2023
-   Population Data: American Community Survey 5-year estimates and decennial
    census data
-   Geographic Analysis: Used block groups rather than counties for finer data
    resolution
-   Geographic Regions: American College of Obstetricians and Gynecologists
    (ACOG) Districts

### Analysis Approach

-   Drive time isochrones (30, 60, 120, 180 minutes) calculated using HERE API
-   Isochrones generated for the third Friday in October at 9:00 AM for each
    year
-   Demographic analysis by race/ethnicity (White, Black, Asian or Pacific
    Islander, American Indian/Alaska Native)
-   Comparison of urban vs. rural accessibility

## Prerequisites

### System Requirements

``` r
# Check R version (minimum 4.0.0 required)
if (getRversion() < "4.0.0") {
  stop("R version 4.0.0 or higher is required. Current version: ", getRversion())
}

# Check available memory (8GB+ recommended)
memory_gb <- round(memory.limit() / 1024, 1)  # Windows
# memory_gb <- round(as.numeric(system("sysctl hw.memsize", intern = TRUE)) / 1024^3, 1)  # macOS
logger::log_info("Available memory: {memory_gb} GB")
if (memory_gb < 8) {
  logger::log_warn("Less than 8GB RAM detected. Large spatial operations may be slow.")
}
```

``` r
# Install required packages
required_packages <- c(
  "tidyverse", "sf", "tigris", "logger", "assertthat",
  "ggplot2", "scales", "viridis", "DT", "knitr"
)

# Install missing packages
new_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)

# Load custom functions
source("R/bespoke_functions.R")
```

-   R 4.0.0 or higher
-   8GB+ RAM recommended for large spatial datasets
-   Required R packages (listed in `01-setup.R`)
-   HERE Maps API key
-   US Census Bureau API key
-   DuckDB database

### HERE Maps Integration

**Geocoding Pipeline:** 1. Address standardization and cleaning 2. Batch
geocoding requests (rate limit management) 3. Quality scoring and manual review
of poor matches 4. Coordinate validation and outlier detection

**Isochrone Generation:** 1. Provider coordinate input 2. Multiple time
threshold requests per provider 3. Polygon simplification for storage efficiency
4. Spatial validation and topology checking

**Why DuckDB over PostgreSQL/SQLite:** - **Performance**: Optimized for
analytical queries (OLAP vs OLTP) - **Simplicity**: Single-file database, no
server required - **Memory**: Efficient handling of large datasets - **R
Integration**: Native R DBI support

**Alternative Considered**: PostgreSQL with PostGIS - **Pros**: Better spatial
functions, multi-user - **Cons**: Server setup complexity, overkill for
single-user analysis

## Tools and Data Management

## 💻 API Configuration

### HERE Maps API Setup

-   Used for geocoding and isochrone generation
-   Geocoding and Search: \$0.83 per 1,000 searches after 30,000 free geocodes
-   Isoline Routing: \$5.50 per 1,000 after 2,500 free isoline routings

``` r
# Set environment variables by adding `HERE_API_KEY=your_here_api_key_here`
# to your `.Renviron` file.
here_key <- Sys.getenv("HERE_API_KEY")
if (!nzchar(here_key)) stop("HERE_API_KEY not set")

# Verify API access
here_status <- httr::GET(
  "https://geocoder.ls.hereapi.com/6.2/geocode.json",
  query = list(apiKey = here_key, searchtext = "test")
)
```

### Census API Setup

``` r
# Install tidycensus if not already installed
if (!require(tidycensus)) install.packages("tidycensus")

# Set Census API key
census_api_key("your_census_api_key_here", install = TRUE)
```

### API Key Setup:

1.  **HERE Maps API**:
    -   Register at <https://developer.here.com/>
    -   Create project, generate API key
    -   Add to `.Renviron`: `HERE_API_KEY=your_key_here`
2.  **Census Bureau API**:
    -   Register at <https://api.census.gov/data/key_signup.html>
    -   Add to `.Renviron`: `CENSUS_API_KEY=your_key_here`

### Data Storage

-   GitHub LFS (Large File Storage) for managing large files
-   DuckDB for efficient data querying
-   PostgreSQL database for year-specific physician data

### Auxiliary Tools

-   tyler package: Custom package for project-specific functions
-   Exploratory.io: Used for data wrangling

## Key Outputs

-   Drive time isochrones at multiple thresholds (30, 60, 120, 180 minutes)
-   Population statistics within/outside isochrones
-   Demographic analysis by race/ethnicity
-   Temporal trends in accessibility (2013-2023)
-   Visualizations of geographic access patterns

## Data Sources

For downloading NPPES files:

``` bash
wget -P "/Volumes/Video Projects Muffly 1/nppes_historical_downloads" "https://download.cms.gov/nppes/NPPES_Data_Dissemination_April_2024.zip"
```

--------------------------------------------------------------------------------

# 📚 Comprehensive Documentation and References {.tabset}

## Methodological Documentation

::: method-box
### **Spatial Analysis Methodology**

Our spatial analysis methodology employs **area-weighted population
calculations** to ensure accurate demographic estimates within isochrone
boundaries:

1.  **Spatial Intersection**: Drive time polygons are intersected with
    high-resolution census block groups
2.  **Area Weighting**: Population estimates are weighted by the proportion of
    block group area within each isochrone\
3.  **Demographic Stratification**: Population counts are stratified by race,
    ethnicity, and other demographic characteristics
4.  **Temporal Consistency**: All calculations use consistent reference times
    and geographic boundaries across analysis years

### **Statistical Analysis Framework**

-   **Trend Analysis**: Linear regression models assess temporal changes
    (2013-2022)
-   **Significance Testing**: P-values calculated at α = 0.05 significance level
-   **Effect Size**: R-squared values quantify variance explained by temporal
    trends
-   **Confidence Intervals**: 95% confidence intervals provided for all change
    estimates
-   **Multiple Comparisons**: Bonferroni corrections applied when testing
    multiple demographic groups
:::

## Technical Implementation Details

```{r technical-implementation, eval=FALSE}
# Advanced technical implementation examples

# Comprehensive isochrone processing with metadata
process_isochrones_with_metadata <- function(provider_sf, 
                                           time_thresholds = c(30, 60, 120, 180),
                                           reference_date = "2023-10-20",
                                           batch_size = 25) {
  
  # Convert time thresholds to seconds
  time_seconds <- time_thresholds * 60
  
  # Create standardized reference time (third Friday of October, 9 AM)
  reference_datetime <- as.POSIXct(paste(reference_date, "09:00:00"), 
                                  format = "%Y-%m-%d %H:%M:%S")
  
  # Initialize comprehensive tracking
  processing_log <- list(
    start_time = Sys.time(),
    total_providers = nrow(provider_sf),
    batch_size = batch_size,
    time_thresholds = time_thresholds,
    reference_datetime = reference_datetime,
    api_calls_made = 0,
    successful_calls = 0,
    failed_calls = 0,
    processing_errors = list()
  )
  
  # Process in batches with comprehensive error handling
  total_batches <- ceiling(nrow(provider_sf) / batch_size)
  all_isochrones <- vector("list", total_batches)
  
  for (batch_num in 1:total_batches) {
    
    start_idx <- (batch_num - 1) * batch_size + 1
    end_idx <- min(batch_num * batch_size, nrow(provider_sf))
    
    batch_providers <- provider_sf[start_idx:end_idx, ]
    
    batch_result <- tryCatch({
      
      # Make API call with comprehensive parameters
      batch_isochrones <- hereR::isoline(
        poi = batch_providers,
        range = time_seconds,
        datetime = reference_datetime,
        routing_mode = "fast",
        range_type = "time",
        transport_mode = "car",
        url_only = FALSE,
        optimize = "balanced", 
        traffic = TRUE,
        aggregate = FALSE
      )
      
      # Add comprehensive metadata
      batch_isochrones$batch_number <- batch_num
      batch_isochrones$processing_timestamp <- Sys.time()
      batch_isochrones$api_version <- "HERE Isoline API v7.2"
      batch_isochrones$reference_datetime <- reference_datetime
      batch_isochrones$traffic_enabled <- TRUE
      batch_isochrones$routing_mode <- "fast"
      
      processing_log$successful_calls <<- processing_log$successful_calls + 1
      
      return(batch_isochrones)
      
    }, error = function(e) {
      
      # Log detailed error information
      error_info <- list(
        batch_number = batch_num,
        error_message = e$message,
        provider_indices = start_idx:end_idx,
        timestamp = Sys.time(),
        provider_count = nrow(batch_providers)
      )
      
      processing_log$processing_errors[[length(processing_log$processing_errors) + 1]] <<- error_info
      processing_log$failed_calls <<- processing_log$failed_calls + 1
      
      return(NULL)
    })
    
    # Store successful results
    if (!is.null(batch_result)) {
      all_isochrones[[batch_num]] <- batch_result
    }
    
    processing_log$api_calls_made <- processing_log$api_calls_made + 1
    
    # Rate limiting between batches
    Sys.sleep(0.3)
  }
  
  # Combine successful results
  successful_isochrones <- Filter(Negate(is.null), all_isochrones)
  
  if (length(successful_isochrones) > 0) {
    combined_isochrones <- do.call(rbind, successful_isochrones)
    
    # Finalize processing log
    processing_log$end_time <- Sys.time()
    processing_log$total_processing_time <- difftime(
      processing_log$end_time, 
      processing_log$start_time, 
      units = "mins"
    )
    processing_log$success_rate <- processing_log$successful_calls / processing_log$api_calls_made
    
    return(list(
      isochrones = combined_isochrones,
      processing_log = processing_log
    ))
  } else {
    stop("No successful isochrone batches generated", call. = FALSE)
  }
}
```

## Data Quality Assurance

::: technical-note
**Quality Assurance Protocol**: Our comprehensive quality assurance system
includes multiple validation layers and cross-verification with independent data
sources.
:::

```{r quality-assurance, eval=FALSE}
# Comprehensive data quality assurance system

comprehensive_quality_assurance <- function(dataset, 
                                          validation_rules = list(),
                                          cross_validation_sources = list()) {
  
  qa_results <- list(
    timestamp = Sys.time(),
    dataset_info = list(
      rows = nrow(dataset),
      columns = ncol(dataset),
      column_names = names(dataset)
    ),
    validation_results = list(),
    cross_validation_results = list(),
    quality_score = NA,
    recommendations = character(0)
  )
  
  # Primary validation checks
  primary_checks <- list(
    missing_data = check_missing_data(dataset),
    duplicate_records = check_duplicates(dataset),
    data_types = validate_data_types(dataset),
    value_ranges = check_value_ranges(dataset),
    referential_integrity = check_referential_integrity(dataset)
  )
  
  qa_results$validation_results <- primary_checks
  
  # Cross-validation with external sources
  if (length(cross_validation_sources) > 0) {
    cross_val_results <- perform_cross_validation(dataset, cross_validation_sources)
    qa_results$cross_validation_results <- cross_val_results
  }
  
  # Calculate composite quality score
  qa_results$quality_score <- calculate_quality_score(qa_results)
  
  # Generate recommendations
  qa_results$recommendations <- generate_quality_recommendations(qa_results)
  
  return(qa_results)
}

# Specific quality checks for healthcare provider data
validate_provider_data <- function(provider_dataset) {
  
  provider_checks <- list(
    
    # NPI validation
    npi_validity = check_npi_validity(provider_dataset$npi),
    
    # Geographic coordinate validation  
    coordinate_validity = validate_coordinates(
      provider_dataset$latitude, 
      provider_dataset$longitude
    ),
    
    # Taxonomy code validation
    taxonomy_validity = validate_taxonomy_codes(provider_dataset$taxonomy),
    
    # Address completeness
    address_completeness = check_address_completeness(provider_dataset),
    
    # Temporal consistency
    temporal_consistency = check_temporal_consistency(provider_dataset),
    
    # Cross-reference validation
    cross_reference_check = cross_reference_with_cms_data(provider_dataset)
  )
  
  return(provider_checks)
}
```

--------------------------------------------------------------------------------

# Key Findings and Policy Implications {.tabset}

## Executive Summary

::: results-box
### **Key Research Findings**

1.  **Baseline Access (2013)**: 44.5% of women had 30-minute access to
    gynecologic oncologists, increasing to 91.3% within 180 minutes

2.  **Temporal Trends**: Generally declining access across all time thresholds,
    though not statistically significant for total population

3.  **Demographic Disparities**: Significant differences by race/ethnicity, with
    Asian women showing increases in longer drive times while White women
    experienced declines

4.  **Geographic Patterns**: Persistent rural-urban divides with metropolitan
    areas maintaining higher accessibility

5.  **Provider Workforce**: Relatively stable provider numbers but shifting
    geographic distribution patterns
:::

## Policy Recommendations

::: highlight-box
### **🏥 Healthcare Policy Implications**

#### **Immediate Actions Needed**

-   **Rural Access Enhancement**: Targeted recruitment and retention programs
    for rural/frontier areas
-   **Telemedicine Integration**: Expanded telehealth capabilities for initial
    consultations and follow-up care
-   **Transportation Assistance**: Patient transportation programs for
    longer-distance specialty care

#### **Long-term Strategic Planning**

-   **Workforce Distribution**: Incentive programs to encourage subspecialist
    practice in underserved regions
-   **Training Pipeline**: Expanded fellowship programs with rural/underserved
    practice requirements
-   **Regional Centers**: Development of regional specialty care centers with
    enhanced accessibility

#### **Health Equity Considerations**

-   **Demographic-Specific Programs**: Targeted outreach and access programs for
    underserved populations
-   **Cultural Competency**: Enhanced cultural competency training for providers
    serving diverse populations
-   **Language Access**: Multilingual care teams and interpretation services
:::

## Future Research Directions

::: method-box
### **🔬 Research Extensions and Innovations**

#### **Methodological Enhancements**

-   **Real-time Traffic Integration**: Dynamic isochrone modeling with
    time-of-day variations
-   **Multi-modal Transportation**: Integration of public transportation and
    ride-sharing options
-   **Provider Capacity Modeling**: Incorporation of provider availability and
    appointment scheduling

#### **Expanded Analysis Scope**

-   **Quality Metrics Integration**: Correlation with care quality and patient
    outcomes
-   **Cost-Effectiveness Analysis**: Economic modeling of accessibility
    improvements
-   **Patient Flow Modeling**: Actual versus potential care utilization patterns

#### **Technology Integration**

-   **Machine Learning Applications**: Predictive modeling for access patterns
    and provider needs
-   **Mobile Health Integration**: Smartphone-based accessibility tools and
    patient navigation
-   **Artificial Intelligence**: AI-powered care coordination and triage systems
:::

--------------------------------------------------------------------------------

# 📧 Contact and Collaboration {.tabset}

## Primary Investigator

::: highlight-box
**Tyler Muffly, MD**\
📧 **Email**: [tyler.muffly\@dhha.org](mailto:tyler.muffly@dhha.org){.email}\
🏥 **Affiliation**: Denver Health and Hospital Authority\
🔗 **Repository**: <https://github.com/mufflyt/isochrones>\
📍 **Location**: Denver, Colorado, USA

### **Research Interests**

-   Healthcare accessibility and geographic disparities
-   Gynecologic oncology workforce analysis\
-   Geospatial health services research
-   Health policy and rural healthcare delivery
:::

## Collaboration Opportunities

We welcome collaborations and contributions from:

-   🎓 **Academic Researchers**: Healthcare services researchers, geographers,
    epidemiologists
-   🏥 **Healthcare Organizations**: Health systems interested in accessibility
    analysis
-   💻 **Technical Contributors**: R developers, GIS specialists, data
    scientists
-   🏛️ **Policy Organizations**: Healthcare policy institutes and government
    agencies

### **How to Contribute**

1.  **🐛 Bug Reports**: Submit issues via GitHub for any technical problems
2.  **📊 Data Contributions**: Share additional validation datasets or provider
    information\
3.  **🔧 Code Improvements**: Submit pull requests for code enhancements
4.  **📖 Documentation**: Help improve documentation and user guides
5.  **🌍 Geographic Extensions**: Adapt methodology for other regions or
    countries

--------------------------------------------------------------------------------

# License and Citation {.tabset}

## License Information

::: technical-note
This project is licensed under the **MIT License**, promoting open science and
reproducible research while ensuring proper attribution.
:::

```         
MIT License

Copyright (c) 2025 Tyler Muffly, MD


``` bash
wget -P "/Volumes/Video Projects Muffly 1/nppes_historical_downloads" "https://download.cms.gov/nppes/NPPES_Data_Dissemination_April_2024.zip"
```

# DATA REFERENCES

```{r, include = TRUE, include=FALSE}
# ==============================================================================
# COPY/PASTE READY REFERENCE VALUES - GYNECOLOGIC ONCOLOGY ACCESSIBILITY PROJECT
# WITH OFFICIAL SOURCES AND CITATIONS
# ==============================================================================

# TAXONOMY CODES FOR OBGYN SUBSPECIALISTS
# Source: National Uniform Claim Committee (NUCC) Health Care Provider Taxonomy
# URL: https://taxonomy.nucc.org/
# Last Updated: Version 23.1 (July 2023)
obgyn_taxonomy_codes <- c(
  "207V00000X",    # Obstetrics & Gynecology (general)
  "207VX0201X",    # Gynecologic Oncology (PRIMARY FOCUS)
  "207VE0102X",    # Reproductive Endocrinology and Infertility
  "207VG0400X",    # Gynecology (general)
  "207VM0101X",    # Maternal & Fetal Medicine
  "207VF0040X",    # Female Pelvic Medicine/Urogynecology
  "207VB0002X",    # Bariatric Medicine
  "207VC0200X",    # Critical Care Medicine
  "207VC0300X",    # Complex Family Planning
  "207VH0002X",    # Hospice and Palliative Medicine
  "207VX0000X"     # Obstetrics only
)

# RUCA CODES (RURAL-URBAN COMMUTING AREAS)
# Source: USDA Economic Research Service
# URL: https://www.ers.usda.gov/data-products/rural-urban-commuting-area-codes/
# Publication: "Rural-Urban Commuting Area Codes" (2010 Census-based, most recent)
# Citation: USDA ERS. Rural-Urban Commuting Area Codes. Washington, DC: Economic Research Service; 2013.
ruca_codes_all <- c(1.0, 1.1, 2.0, 2.1, 3.0, 4.1, 4.2, 5.0, 5.1, 6.0, 6.1, 
                   7.0, 7.1, 7.2, 7.3, 7.4, 8.0, 8.1, 8.2, 8.3, 8.4, 9.0, 
                   10.0, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6)

# RUCA SIMPLIFIED CATEGORIES
# Source: Hart LG, Larson EH, Lishner DM. Rural definitions for health policy research. 
# Am J Public Health. 2005;95(7):1149-1155.
# Also: Morrill R, Cromartie J, Hart G. Metropolitan, urban, and rural commuting areas: 
# toward a better depiction of the United States settlement system. Urban Geography. 1999;20(8):727-748.
ruca_metropolitan <- c(1.0, 1.1, 2.0, 2.1, 3.0)       # Large metro areas
ruca_micropolitan <- c(4.1, 4.2, 5.0, 5.1, 6.0, 6.1)  # Mid-size cities  
ruca_small_town <- c(7.0, 7.1, 7.2, 7.3, 7.4, 8.0, 8.1, 8.2, 8.3, 8.4)  # Small towns
ruca_rural <- c(9.0, 10.0, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6)  # Rural areas

# US CENSUS REGIONS AND DIVISIONS
# Source: US Census Bureau Geography Division
# URL: https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf
# Publication: "Geographic Areas Reference Manual" Chapter 6
# Citation: US Census Bureau. Geographic Areas Reference Manual. Washington, DC: US Census Bureau; 1994.
# Official Definition: Title 13, United States Code, Section 4
census_regions <- c("Northeast", "Midwest", "South", "West")
census_divisions <- c("New England", "Middle Atlantic", "East North Central", 
                     "West North Central", "South Atlantic", "East South Central",
                     "West South Central", "Mountain", "Pacific")

# STATE ABBREVIATIONS BY CENSUS REGION
# Source: US Census Bureau, Geography Division
# URL: https://www.census.gov/geographies/reference-files/2010/geo/state-area.html
# Note: Established by Federal Information Processing Standards (FIPS) Publication 5-2
northeast_states <- c("CT", "ME", "MA", "NH", "RI", "VT", "NJ", "NY", "PA")
midwest_states <- c("IL", "IN", "MI", "OH", "WI", "IA", "KS", "MN", "MO", "NE", "ND", "SD")
south_states <- c("DE", "FL", "GA", "MD", "NC", "SC", "VA", "WV", "DC", "AL", "KY", "MS", "TN", "AR", "LA", "OK", "TX")
west_states <- c("AZ", "CO", "ID", "MT", "NV", "NM", "UT", "WY", "AK", "CA", "HI", "OR", "WA")

# ACOG DISTRICTS BY STATE
# Source: American College of Obstetricians and Gynecologists
# URL: https://www.acog.org/about/districts-and-sections
# Publication: ACOG Organization Manual, current as of 2023
# Citation: American College of Obstetricians and Gynecologists. District Organization. Washington, DC: ACOG; 2023.
acog_district_1 <- c("CT", "ME", "MA", "NH", "RI", "VT")  # New England
acog_district_2 <- c("NY")  # New York Metro
acog_district_3 <- c("DE", "NJ", "PA")  # Mid-Atlantic
acog_district_4 <- c("DC", "MD", "VA", "WV")  # Southeast
acog_district_5 <- c("AL", "FL", "GA", "MS", "SC", "TN")  # Southeast
acog_district_6 <- c("IL", "IN", "IA", "KY", "MN", "MO", "NE", "ND", "OH", "SD", "WI")  # Midwest/Plains
acog_district_7 <- c("AZ", "CO", "NV", "NM", "UT", "WY")  # Mountain West
acog_district_8 <- c("AK", "ID", "MT", "OR", "WA")  # Pacific Northwest
acog_district_9 <- c("CA", "HI")  # Pacific West
acog_district_10 <- c("AR", "KS", "LA", "OK", "TX")  # South Central
acog_district_11 <- c("MI", "NC")  # Great Lakes/Southeast

# ALL US STATES AND TERRITORIES
# Source: Federal Information Processing Standards (FIPS) Publication 5-2
# URL: https://www.census.gov/library/reference/code-lists/ansi.html
# Citation: National Institute of Standards and Technology. FIPS PUB 5-2: Codes for the Identification of the States. Gaithersburg, MD: NIST; 1987.
all_states <- c("AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA", 
               "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD",
               "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ",
               "NM", "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", 
               "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY", "DC")

us_territories <- c("AS", "GU", "MP", "PR", "VI")  # American Samoa, Guam, N. Mariana Islands, Puerto Rico, Virgin Islands

# STATE FIPS CODES
# Source: Federal Information Processing Standards (FIPS) Publication 5-2
# URL: https://www.census.gov/library/reference/code-lists/ansi.html
# Citation: Same as above
state_fips <- c("01", "02", "04", "05", "06", "08", "09", "10", "12", "13",
               "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", 
               "25", "26", "27", "28", "29", "30", "31", "32", "33", "34",
               "35", "36", "37", "38", "39", "40", "41", "42", "44", "45",
               "46", "47", "48", "49", "50", "51", "53", "54", "55", "56", "11")

# REFERENCE DATES - THIRD FRIDAY OCTOBER 9AM (2013-2023)
# Source: Project methodology decision
# Rationale: Standardized weekday morning time to avoid rush hour peaks and ensure consistency
# Citation: Muffly T. Gynecologic Oncology Accessibility Project Methodology. 2024.
reference_dates_2013_2023 <- c(
  "2013-10-18", "2014-10-17", "2015-10-16", "2016-10-21", "2017-10-20",
  "2018-10-19", "2019-10-18", "2020-10-16", "2021-10-15", "2022-10-21", "2023-10-20"
)

# ISO DATETIME FORMAT FOR API CALLS
# Source: ISO 8601 Standard for date/time representation
# URL: https://www.iso.org/iso-8601-date-and-time-format.html
iso_datetime_2013_2023 <- c(
  "2013-10-18T09:00:00", "2014-10-17T09:00:00", "2015-10-16T09:00:00",
  "2016-10-21T09:00:00", "2017-10-20T09:00:00", "2018-10-19T09:00:00",
  "2019-10-18T09:00:00", "2020-10-16T09:00:00", "2021-10-15T09:00:00", 
  "2022-10-21T09:00:00", "2023-10-20T09:00:00"
)

# DRIVE TIME THRESHOLDS
# Source: Healthcare accessibility literature standards
# Citations: 
# - Penchansky R, Thomas JW. The concept of access: definition and relationship to consumer satisfaction. Med Care. 1981;19(2):127-140.
# - Wang F, Luo W. Assessing spatial and nonspatial factors for healthcare access: towards an integrated approach to defining health professional shortage areas. Health Place. 2005;11(2):131-146.
drive_times_minutes <- c(30, 60, 120, 180)
drive_times_seconds <- c(1800, 3600, 7200, 10800)  # For HERE API

# COORDINATE REFERENCE SYSTEMS (EPSG CODES)
# Source: European Petroleum Survey Group (EPSG) Geodetic Parameter Dataset
# URL: https://epsg.org/
# Citation: EPSG. EPSG Geodetic Parameter Dataset. Oil & Gas Producers Association; 2023.
epsg_wgs84 <- 4326          # WGS84 Geographic (input coordinates)
epsg_web_mercator <- 3857   # Web Mercator (web display)
epsg_us_albers <- 5070      # US Albers Equal Area (analysis)
epsg_alaska_albers <- 3338  # Alaska Albers
epsg_hawaii_albers <- 4135  # Hawaii Albers

# CENSUS VARIABLES (ACS 5-YEAR)
# Source: US Census Bureau American Community Survey
# URL: https://www.census.gov/programs-surveys/acs/guidance/subjects.html
# Publication: American Community Survey Subject Definitions
# Citation: US Census Bureau. American Community Survey Subject Definitions. Washington, DC: US Census Bureau; 2021.
census_total_population <- "B01003_001"
census_female_population <- "B01001_026"
census_white_alone <- "B03002_003"
census_black_alone <- "B03002_004"
census_asian_alone <- "B03002_006"
census_aian_alone <- "B03002_005"  # American Indian/Alaska Native
census_median_income <- "B19013_001"
census_housing_units <- "B25001_001"

# HERE API ENDPOINTS
# Source: HERE Technologies Developer Documentation
# URL: https://developer.here.com/documentation/
# Citation: HERE Technologies. HERE Platform Developer Guide. Eindhoven, Netherlands: HERE; 2023.
here_geocoding_url <- "https://geocoder.ls.hereapi.com/6.2/geocode.json"
here_reverse_geocoding_url <- "https://reverse.geocoder.ls.hereapi.com/6.2/reversegeocode.json"
here_isoline_url <- "https://isoline.route.ls.hereapi.com/routing/7.2/calculateisoline.json"

# HERE API PARAMETERS
# Source: HERE Routing API Documentation
# URL: https://developer.here.com/documentation/routing-api/dev_guide/topics/resource-calculate-isoline.html
here_isoline_mode <- "car"
here_isoline_traffic <- "enabled"
here_isoline_rangetype <- "time"
here_isoline_resolution <- 1    # Highest resolution
here_isoline_maxpoints <- 1000  # Maximum polygon points
here_isoline_quality <- 1       # Highest quality

# US TIMEZONES
# Source: Internet Assigned Numbers Authority (IANA) Time Zone Database
# URL: https://www.iana.org/time-zones
# Citation: IANA. Time Zone Database. Internet Assigned Numbers Authority; 2023.
us_timezones <- c("America/New_York", "America/Chicago", "America/Denver", 
                 "America/Los_Angeles", "America/Anchorage", "Pacific/Honolulu")
timezone_names <- c("Eastern", "Central", "Mountain", "Pacific", "Alaska", "Hawaii")

# MAJOR METROPOLITAN AREAS (CBSAs)
# Source: Office of Management and Budget
# URL: https://www.whitehouse.gov/omb/management/office-federal-financial-management/
# Publication: OMB Bulletin No. 20-01 (March 6, 2020)
# Citation: Office of Management and Budget. Revised Delineations of Metropolitan Statistical Areas, Micropolitan Statistical Areas, and Combined Statistical Areas. Washington, DC: OMB; 2020.
major_cbsa_codes <- c("35620", "31080", "16980", "19100", "26420", "33460", "37980", 
                     "40140", "41860", "47900", "12060", "14460", "41740", "38060")

major_msa_names <- c(
  "New York-Newark-Jersey City, NY-NJ-PA",
  "Los Angeles-Long Beach-Anaheim, CA", 
  "Chicago-Naperville-Elgin, IL-IN-WI",
  "Dallas-Fort Worth-Arlington, TX",
  "Houston-The Woodlands-Sugar Land, TX",
  "Miami-Fort Lauderdale-West Palm Beach, FL",
  "Philadelphia-Camden-Wilmington, PA-NJ-DE-MD",
  "Riverside-San Bernardino-Ontario, CA",
  "San Francisco-Oakland-Hayward, CA",
  "Washington-Arlington-Alexandria, DC-VA-MD-WV",
  "Atlanta-Sandy Springs-Roswell, GA", 
  "Boston-Cambridge-Newton, MA-NH",
  "San Antonio-New Braunfels, TX",
  "Phoenix-Mesa-Scottsdale, AZ"
)

# MAJOR INTERSTATE HIGHWAYS
# Source: Federal Highway Administration
# URL: https://www.fhwa.dot.gov/planning/national_highway_system/
# Publication: National Highway System
# Citation: Federal Highway Administration. National Highway System. Washington, DC: US Department of Transportation; 2023.

# East-West Interstates
interstate_east_west <- c("I-10", "I-20", "I-30", "I-40", "I-70", "I-80", "I-90")

# North-South Interstates  
interstate_north_south <- c("I-5", "I-15", "I-25", "I-35", "I-65", "I-75", "I-85", "I-95")

# All Major Interstates
all_major_interstates <- c(interstate_east_west, interstate_north_south)

# VALIDATION THRESHOLDS
# Source: Project quality control standards based on literature review
# Citations:
# - Baldwin LM, et al. Access to specialty health care for rural American Indians in the northwest. Med Care. 2008;46(12):1218-1224.
# - Onega T, et al. Geographic access to cancer care in the U.S. Cancer. 2008;112(4):909-918.
min_provider_count <- 40000      # Minimum NPPES providers expected
min_gyn_onc_count <- 1000       # Minimum gynecologic oncologists
min_geocoding_success <- 0.85   # Minimum geocoding success rate
min_isochrone_success <- 0.90   # Minimum isochrone generation success
min_population_coverage <- 0.95 # Minimum census population coverage

# QUALITY CONTROL RANGES
# Source: US Geological Survey Geographic Names Information System
# URL: https://geonames.usgs.gov/domestic/
# Citation: US Geological Survey. Geographic Names Information System. Reston, VA: USGS; 2023.
max_coordinate_lat <- 71.5      # Northernmost US point (Alaska)
min_coordinate_lat <- 18.9      # Southernmost US point (Hawaii) 
max_coordinate_lon <- -66.9     # Easternmost US point (Maine)
min_coordinate_lon <- -179.1    # Westernmost US point (Alaska)

# CENSUS GEOGRAPHY COUNTS (2020 Census)
# Source: US Census Bureau Geography Division
# URL: https://www.census.gov/geographies/reference-files/2020/geo/tallies/
# Publication: 2020 Census Geographic Tallies
# Citation: US Census Bureau. 2020 Census Geographic Tallies. Washington, DC: US Census Bureau; 2021.
census_2020_states <- 51           # 50 states + DC
census_2020_counties <- 3143       # Total counties
census_2020_tracts <- 84414        # Census tracts
census_2020_block_groups <- 242335 # Block groups

# API RATE LIMITS
# Source: HERE Technologies Developer Portal
# URL: https://developer.here.com/pricing
# Current as of: 2023
here_geocoding_free_limit <- 30000    # Per month
here_isoline_free_limit <- 2500       # Per month
census_api_daily_limit <- 500         # Without API key

# DIRECTORY STRUCTURE
# Source: Project organization standards following best practices
# Citation: Wilson G, et al. Good enough practices in scientific computing. PLoS Comput Biol. 2017;13(6):e1005510.
dir_data_raw <- "data/raw/"
dir_data_processed <- "data/processed/"
dir_data_geocoded <- "data/geocoded/"
dir_data_spatial <- "data/spatial/"
dir_results <- "results/"
dir_figures <- "figures/"
dir_cache <- "cache/"
```

# URL Reference Table - Gynecologic Oncology Accessibility Project

## Data Sources - Primary

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| NPPES (National Plan and Provider Enumeration System) | <https://nppes.cms.hhs.gov/> | Primary provider registry | Public |
| NBER NPPES Historical Data | <https://www.nber.org/research/data/national-plan-and-provider-enumeration-system-nppes-data> | Historical provider data 2007-2022 | Public |
| CMS Medicare Part D Prescriber Data | <https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Part-D-Prescriber> | Annual prescribing patterns | Public |
| CMS Physician Compare (Historical) | <https://www.openicpsr.org/openicpsr/project/149961/version/V1/view> | Historical physician data through 2020 | Requires Login |
| CMS Open Payments (Sunshine Act) | <https://openpaymentsdata.cms.gov/> | Industry payments to physicians | Public |
| CMS Provider Enrollment Data | <https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data> | Provider enrollment and specialty | Public |
| NPPES Data Dissemination | <https://download.cms.gov/nppes/NPI_Files.html> | Monthly NPPES data downloads | Public |
| CMS Data Navigator | <https://www.cms.gov/data-research/statistics-trends-and-reports/cms-data-navigator> | CMS data portal and navigation | Public |

## Census & Geographic Data

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| US Census Bureau API | <https://api.census.gov/data.html> | Main census data API portal | Public |
| American Community Survey (ACS) | <https://www.census.gov/programs-surveys/acs> | Population and demographic data | Public |
| TIGER/Line Shapefiles | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Geographic boundary files | Public |
| Census Geography Products | <https://www.census.gov/programs-surveys/geography.html> | Geographic concepts and products | Public |
| Rural-Urban Commuting Area Codes | <https://www.ers.usda.gov/data-products/rural-urban-commuting-area-codes/> | RUCA classification system | Public |
| Metropolitan Statistical Areas | <https://www.census.gov/programs-surveys/metro-micro.html> | MSA definitions and data | Public |
| Census API Key Registration | <https://api.census.gov/data/key_signup.html> | Free API key registration | Registration |
| Federal Information Processing Standards | <https://www.census.gov/library/reference/code-lists/ansi.html> | FIPS codes and standards | Public |

## API Documentation

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| HERE Maps Developer Portal | <https://developer.here.com/> | HERE API registration and docs | API Key Required |
| HERE Geocoding API Documentation | <https://developer.here.com/documentation/geocoder/> | Address geocoding documentation | API Key Required |
| HERE Isoline Routing API | <https://developer.here.com/documentation/routing-api/> | Drive time isochrone generation | API Key Required |
| Census Bureau API Documentation | <https://www.census.gov/data/developers/guidance.html> | Census API usage guidelines | Public |
| HERE API Pricing | <https://developer.here.com/pricing> | Rate limits and pricing tiers | Public |
| REST API Best Practices | <https://developer.here.com/documentation/identity-access-management/dev_guide/topics/plat-using-apikeys.html> | API key management | Public |

## Healthcare & Medical Resources

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| NUCC Health Care Provider Taxonomy | <https://taxonomy.nucc.org/> | Official provider taxonomy codes | Public |
| ACOG (American College of Obstetricians and Gynecologists) | <https://www.acog.org/> | Professional organization | Public |
| ACOG Districts | <https://www.acog.org/about/districts-and-sections> | Geographic district organization | Public |
| Society of Gynecologic Oncology | <https://www.sgo.org/> | Subspecialty professional society | Public |
| NCCN Guidelines (Gynecologic Oncology) | <https://www.nccn.org/guidelines/category_1> | Clinical practice guidelines | Registration |
| ACGME Fellowship Requirements | <https://www.acgme.org/specialties/> | Fellowship training requirements | Public |
| AAMC Physician Workforce Data | <https://www.aamc.org/data-reports/workforce/data> | Physician workforce statistics | Public |
| HRSA Health Professional Shortage Areas | <https://data.hrsa.gov/tools/shortage-area> | Underserved area designations | Public |

## Government Resources

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| CMS (Centers for Medicare & Medicaid Services) | <https://www.cms.gov/> | Primary healthcare data agency | Public |
| HRSA (Health Resources and Services Administration) | <https://www.hrsa.gov/> | Federal health workforce agency | Public |
| USDA Economic Research Service | <https://www.ers.usda.gov/> | Rural-urban classifications | Public |
| OMB Metropolitan Area Delineations | <https://www.whitehouse.gov/omb/management/office-federal-financial-management/> | Official MSA definitions | Public |
| HHS Data Portal | <https://healthdata.gov/> | Federal health data catalog | Public |
| National Cancer Institute | <https://www.cancer.gov/> | Cancer statistics and resources | Public |
| Federal Geographic Data Committee | <https://www.fgdc.gov/> | Geographic data standards | Public |

## Technical Documentation

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| R Project | <https://www.r-project.org/> | R statistical software | Open Source |
| RStudio | <https://www.rstudio.com/> | R development environment | Free/Commercial |
| sf R Package Documentation | <https://r-spatial.github.io/sf/> | Spatial features for R | Open Source |
| tigris R Package | <https://github.com/walkerke/tigris> | Census geography in R | Open Source |
| DuckDB Documentation | <https://duckdb.org/docs/> | Analytical database engine | Open Source |
| GDAL Documentation | <https://gdal.org/> | Geospatial data abstraction library | Open Source |
| PROJ Coordinate Transformation | <https://proj.org/> | Cartographic projections library | Open Source |
| PostGIS Documentation | <https://postgis.net/documentation/> | Spatial database extension | Open Source |
| GitHub Repository Best Practices | <https://docs.github.com/en/repositories> | Version control and collaboration | Public |

## Academic & Research Resources

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| PubMed | <https://pubmed.ncbi.nlm.nih.gov/> | Medical literature database | Public |
| SEER Cancer Statistics | <https://seer.cancer.gov/> | National cancer surveillance | Public |
| Health Affairs Journal | <https://www.healthaffairs.org/> | Health policy research | Subscription |
| Medical Care Research and Review | <https://journals.sagepub.com/home/mcr> | Healthcare access research | Subscription |
| Spatial and Spatio-temporal Epidemiology | <https://www.journals.elsevier.com/spatial-and-spatio-temporal-epidemiology> | Spatial health analysis | Subscription |
| International Journal of Health Geographics | <https://ij-healthgeographics.biomedcentral.com/> | Health geography research | Open Access |

## Software & Tools

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| CRAN (R Package Repository) | <https://cran.r-project.org/> | R package downloads | Open Source |
| GitHub | <https://github.com/> | Code repository and collaboration | Free/Paid |
| Docker Hub | <https://hub.docker.com/> | Container registry | Free/Paid |
| Conda Package Manager | <https://docs.conda.io/> | Package management system | Open Source |
| renv R Package | <https://rstudio.github.io/renv/> | R environment management | Open Source |
| Git Documentation | <https://git-scm.com/doc> | Version control system | Open Source |
| Zenodo | <https://zenodo.org/> | Research data repository | Free |
| Open Science Framework | <https://osf.io/> | Research project management | Free |

## Professional Organizations & Standards

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| American Medical Association | <https://www.ama-assn.org/> | Medical professional organization | Public |
| Association of American Medical Colleges | <https://www.aamc.org/> | Medical education organization | Public |
| National Quality Forum | <https://www.qualityforum.org/> | Healthcare quality standards | Public |
| International Association of Geographers | <https://iag-online.org/> | Geographic research organization | Public |
| American Statistical Association | <https://www.amstat.org/> | Statistical methods and standards | Public |

## Data Standards & Metadata

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| HL7 FHIR Standards | <https://www.hl7.org/fhir/> | Healthcare data exchange standards | Public |
| ISO Geographic Standards | <https://www.iso.org/committee/54904.html> | International geographic standards | Public |
| OGC Standards | <https://www.ogc.org/standards> | Geospatial data standards | Public |
| Dublin Core Metadata | <https://www.dublincore.org/> | Metadata standards | Public |
| Schema.org | <https://schema.org/> | Structured data vocabulary | Public |

## Quality Control & Validation

| Resource Name | URL | Description | Access Type |
|----|----|----|----|
| American Community Survey Accuracy Statement | <https://www.census.gov/programs-surveys/acs/guidance/statistical-testing-tool.html> | ACS data accuracy guidelines | Public |
| HERE Map Quality | <https://developer.here.com/documentation/routing-api/dev_guide/topics/resource-calculate-isoline.html> | API data quality specifications | API Documentation |
| CMS Data Quality Assurance | <https://www.cms.gov/Research-Statistics-Data-and-Systems/CMS-Information-Technology/AccesstoDataApplication/DataUseAgreements> | Data quality standards | Public |
| Spatial Data Quality Standards | <https://www.fgdc.gov/standards/projects/framework-data-standard> | Federal spatial data quality | Public |

# SHAPEFILE - Geographic Boundaries for Healthcare Accessibility Analysis

# Simplified US Boundaries Reference

## US Census Bureau Cartographic Boundary Files (Simplified)

### Country/National Boundaries

| Resolution | File Name Pattern | Download URL | File Size | Use Case |
|----|----|----|----|----|
| **20m (High Detail)** | `cb_2021_us_nation_20m.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~50MB | Detailed national analysis |
| **5m (Medium Detail)** | `cb_2021_us_nation_5m.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~20MB | General national mapping |
| **500k (Low Detail)** | `cb_2021_us_nation_500k.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~5MB | Web mapping, overview maps |

### State Boundaries (Simplified)

| Resolution | File Name Pattern | Download URL | File Size | Use Case |
|----|----|----|----|----|
| **20m (High Detail)** | `cb_2021_us_state_20m.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~25MB | Detailed state analysis |
| **5m (Medium Detail)** | `cb_2021_us_state_5m.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~8MB | **RECOMMENDED for most analysis** |
| **500k (Low Detail)** | `cb_2021_us_state_500k.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~2MB | Web display, overview maps |

### County Boundaries (Simplified)

| Resolution | File Name Pattern | Download URL | File Size | Use Case |
|----|----|----|----|----|
| **20m** | `cb_2021_us_county_20m.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~45MB | Detailed county analysis |
| **5m** | `cb_2021_us_county_5m.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~15MB | **RECOMMENDED** |
| **500k** | `cb_2021_us_county_500k.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~4MB | Web mapping |

### Census Tract Boundaries (Simplified)

| Resolution | File Name Pattern | Download URL | File Size | Use Case |
|----|----|----|----|----|
| **National 500k** | `cb_2021_us_tract_500k.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~180MB | **National tract analysis** |
| **State-by-State 500k** | `cb_2021_[FIPS]_tract_500k.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | 1-20MB each | State-specific analysis |

**Example State Files:** - Colorado: `cb_2021_08_tract_500k.zip` - California:
`cb_2021_06_tract_500k.zip`\
- Texas: `cb_2021_48_tract_500k.zip` - New York: `cb_2021_36_tract_500k.zip`

### Block Group Boundaries (Simplified)

| File Type | File Name Pattern | Download URL | File Size | Notes |
|----|----|----|----|----|
| **National** | `cb_2021_us_bg_500k.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | \~350MB | Similar to your `simplified_us_lck_grp_2021.shp` |
| **State-by-State** | `cb_2021_[FIPS]_bg_500k.zip` | <https://www2.census.gov/geo/tiger/GENZ2021/shp/> | 2-40MB each | Smaller, manageable files |

## R Package Sources for Simplified Boundaries

### tigris Package (Automatic Simplification)

``` r
# Simplified boundaries with cb = TRUE parameter
library(tigris)

# US States (simplified)
states_simplified <- tigris::states(cb = TRUE, resolution = "20m")  # or "5m", "500k"

# US Counties (simplified)  
counties_simplified <- tigris::counties(cb = TRUE, resolution = "20m")

# Census Tracts (simplified) - by state
colorado_tracts <- tigris::tracts(state = "CO", cb = TRUE)

# Block Groups (simplified) - by state  
colorado_bg <- tigris::block_groups(state = "CO", cb = TRUE)

# National boundaries
us_nation <- tigris::nation(cb = TRUE, resolution = "5m")
```

### USAboundaries Package (Historical + Simplified)

``` r
library(USAboundaries)

# Current simplified state boundaries
states_2020 <- us_states(resolution = "low")    # Simplified
states_2020_hi <- us_states(resolution = "high") # Detailed

# Current simplified county boundaries  
counties_2020 <- us_counties(resolution = "low")

# Historical boundaries (simplified)
states_1990 <- us_states(map_date = "1990-01-01", resolution = "low")
```

## Alternative Simplified Boundary Sources

### Natural Earth (Global, Multi-Scale)

| Scale | Resolution | Download URL | US Coverage |
|----|----|----|----|
| **1:10m** | High detail | <https://www.naturalearthdata.com/downloads/10m-cultural-vectors/> | Detailed US boundaries |
| **1:50m** | Medium detail | <https://www.naturalearthdata.com/downloads/50m-cultural-vectors/> | **RECOMMENDED** |
| **1:110m** | Low detail | <https://www.naturalearthdata.com/downloads/110m-cultural-vectors/> | Overview mapping |

**Specific Files:** - Countries: `ne_50m_admin_0_countries.zip` -
States/Provinces: `ne_50m_admin_1_states_provinces.zip`

### OpenStreetMap (Simplified Extracts)

| Source | Description | Download URL | Format |
|----|----|----|----|
| **Geofabrik** | US state extracts | <https://download.geofabrik.de/north-america/us/> | Various formats |
| **BBBike** | Custom extracts | <https://extract.bbbike.org/> | Shapefile, GeoJSON |

# Creating Your Own Simplified Boundaries

### Using R (sf package)

``` r
library(sf)

# Load detailed boundary
detailed_boundary <- st_read("detailed_boundary.shp")

# Simplify geometry (tolerance in map units)
simplified_boundary <- st_simplify(detailed_boundary, dTolerance = 1000)  # 1km tolerance

# Alternative: preserve topology
simplified_boundary <- st_simplify(detailed_boundary, preserveTopology = TRUE, dTolerance = 500)

# Save simplified version
st_write(simplified_boundary, "simplified_boundary.shp")
```

## R Code Examples for Common Use Cases

### Load All Simplified Boundaries

``` r
library(tigris)
library(sf)

# Set options for simplified boundaries
options(tigris_use_cache = TRUE)  # Cache for faster repeated access

# Load simplified boundaries
us_states <- tigris::states(cb = TRUE, resolution = "5m")
us_counties <- tigris::counties(cb = TRUE, resolution = "5m") 
us_nation <- tigris::nation(cb = TRUE, resolution = "5m")

# Load census tracts for specific states (simplified)
colorado_tracts <- tigris::tracts(state = "CO", cb = TRUE)
california_tracts <- tigris::tracts(state = "CA", cb = TRUE)

# Load block groups for analysis (similar to your file)
colorado_bg <- tigris::block_groups(state = "CO", cb = TRUE)
```

### Performance Comparison

| Boundary Type     | Detailed Size | Simplified Size | Speed Improvement    |
|-------------------|---------------|-----------------|----------------------|
| **US States**     | \~15MB        | \~8MB           | 2x faster rendering  |
| **US Counties**   | \~80MB        | \~15MB          | 5x faster rendering  |
| **Census Tracts** | \~1.2GB       | \~180MB         | 10x faster rendering |
| **Block Groups**  | \~2.5GB       | \~350MB         | 15x faster rendering |

## Quality Control for Simplified Boundaries

### Validation Checks

``` r
# Check validity of simplified geometries
st_is_valid(simplified_boundary)

# Fix invalid geometries if needed
simplified_boundary <- st_make_valid(simplified_boundary)

# Check area preservation (should be close to original)
original_area <- sum(st_area(detailed_boundary))
simplified_area <- sum(st_area(simplified_boundary))
area_difference <- abs(simplified_area - original_area) / original_area
print(paste("Area difference:", scales::percent(area_difference)))
```

## File Naming Convention Reference

### Census Bureau Pattern

-   `cb_[YEAR]_[GEOGRAPHY]_[ENTITY]_[RESOLUTION].zip`
-   Examples:
    -   `cb_2021_us_state_5m.zip` (US states, 5m resolution)
    -   `cb_2021_08_tract_500k.zip` (Colorado tracts, 500k resolution)
    -   `cb_2021_us_bg_500k.zip` (US block groups, 500k resolution)

### Resolution Codes

-   **20m**: 1:20,000,000 scale (high detail)
-   **5m**: 1:5,000,000 scale (medium detail)\
-   **500k**: 1:500,000 scale (low detail, most simplified)

The **500k resolution** files are closest to your
`simplified_us_lck_grp_2021.shp` pattern and are optimized for analytical work
while maintaining essential geographic accuracy.

# US Census Bureau Geographic Boundaries

| Geographic Unit | Data Source | Download URL | File Format | Coverage | Update Frequency | Notes |
|----|----|----|----|----|----|----|
| **Census Tracts** | US Census Bureau | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile, KML, GeoJSON | National, State, County | Annual | Primary analysis unit for demographics |
| **Census Block Groups** | US Census Bureau | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile, KML, GeoJSON | National, State, County | Annual | Highest resolution demographic data |
| **Census Blocks** | US Census Bureau | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile, KML, GeoJSON | National, State, County | Annual | Most detailed geographic unit |
| **State Boundaries** | US Census Bureau | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile, KML, GeoJSON | National | Annual | State-level analysis |
| **County Boundaries** | US Census Bureau | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile, KML, GeoJSON | National, State | Annual | County-level aggregation |
| **ZIP Code Tabulation Areas (ZCTAs)** | US Census Bureau | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile, KML, GeoJSON | National | Decennial Census | Approximate ZIP code areas |
| **Urban Areas** | US Census Bureau | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile, KML, GeoJSON | National | Decennial Census | Urban vs rural classification |

## Health Resources and Services Administration (HRSA) Areas

| Geographic Unit | Data Source | Download URL | File Format | Coverage | Update Frequency | Notes |
|----|----|----|----|----|----|----|
| **Health Professional Shortage Areas (HPSAs)** | HRSA | <https://data.hrsa.gov/data/download> | Shapefile, GeoJSON, CSV | National | Quarterly | Primary care, dental, mental health |
| **Medically Underserved Areas (MUAs)** | HRSA | <https://data.hrsa.gov/data/download> | Shapefile, GeoJSON, CSV | National | Quarterly | Areas lacking medical care |
| **Medically Underserved Populations (MUPs)** | HRSA | <https://data.hrsa.gov/data/download> | Shapefile, GeoJSON, CSV | National | Quarterly | Population-based designations |
| **Federally Qualified Health Centers (FQHCs)** | HRSA | <https://data.hrsa.gov/data/download> | Point data, CSV | National | Monthly | FQHC locations |
| **Rural Health Clinics** | HRSA | <https://data.hrsa.gov/data/download> | Point data, CSV | National | Monthly | RHC locations |
| **Critical Access Hospitals** | HRSA | <https://data.hrsa.gov/data/download> | Point data, CSV | National | Monthly | CAH locations |

## Rural-Urban Classifications

| Geographic Unit | Data Source | Download URL | File Format | Coverage | Update Frequency | Notes |
|----|----|----|----|----|----|----|
| **Rural-Urban Commuting Areas (RUCAs)** | USDA ERS | <https://www.ers.usda.gov/data-products/rural-urban-commuting-area-codes/documentation/> | CSV with FIPS codes | National (Census Tracts) | \~10 years | 2010 Census-based (most recent) |
| **Urban Influence Codes** | USDA ERS | <https://www.ers.usda.gov/data-products/urban-influence-codes/> | CSV with FIPS codes | National (Counties) | \~10 years | County-level rural-urban |
| **Rural-Urban Continuum Codes** | USDA ERS | <https://www.ers.usda.gov/data-products/rural-urban-continuum-codes/> | CSV with FIPS codes | National (Counties) | \~10 years | Metro and non-metro counties |

## ACOG Districts and Medical Professional Areas

| Geographic Unit | Data Source | Download URL | File Format | Coverage | Update Frequency | Notes |
|----|----|----|----|----|----|----|
| **Hospital Referral Regions (HRRs)** | Dartmouth Atlas | <https://www.dartmouthatlas.org/tools/downloads.aspx> | Shapefile | National | \~10 years | Healthcare market areas |
| **Hospital Service Areas (HSAs)** | Dartmouth Atlas | <https://www.dartmouthatlas.org/tools/downloads.aspx> | Shapefile | National | \~10 years | Local hospital markets |

## Transportation and Infrastructure

| Geographic Unit | Data Source | Download URL | File Format | Coverage | Update Frequency | Notes |
|----|----|----|----|----|----|----|
| **Primary Roads** | US Census Bureau | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | National, State | Annual | Major highways and roads |
| **All Roads** | US Census Bureau | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | National, State, County | Annual | Complete road network |

## Major Highway Systems and Interstate Corridors

| Highway System | Data Source | Download URL | File Format | Coverage | Update Frequency | Specific Routes Included |
|----|----|----|----|----|----|----|
| **Interstate Highway System** | US Census Bureau TIGER | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | National | Annual | I-95, I-10, I-5, I-75, I-80, I-40, I-35, I-25, I-70, I-90, etc. |
| **US Highway System** | US Census Bureau TIGER | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | National | Annual | US-1, US-50, US-101, US-Route 66 (historic), etc. |
| **Primary Roads (Interstate + US)** | US Census Bureau TIGER | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | National | Annual | All Interstate and US highways combined |
| **National Highway System (NHS)** | FHWA | <https://www.fhwa.dot.gov/planning/national_highway_system/> | Shapefile, GeoJSON | National | Annual | Congressionally designated strategic highways |

## Major Interstate Highways (Detailed Reference)

### East-West Interstate Corridors

| Route | Description | States Traversed | Length (Miles) | Key Cities Connected | Healthcare Relevance |
|----|----|----|----|----|----|
| **I-10** | Southern transcontinental | CA, AZ, NM, TX, LA, MS, AL, FL | 2,460 | Los Angeles - Houston - New Orleans - Jacksonville | Major Sun Belt corridor |
| **I-20** | Southern route | TX, LA, MS, AL, GA, SC | 1,535 | Dallas - Atlanta - Columbia | Connects major Southern medical centers |
| **I-30** | Arkansas-Texas | TX, AR | 367 | Dallas - Little Rock | Links Dallas medical district |
| **I-40** | Central transcontinental | CA, AZ, NM, TX, OK, AR, TN, NC | 2,555 | Los Angeles - Nashville - Raleigh | Major cross-country medical corridor |
| **I-70** | Central route | UT, CO, KS, MO, IL, IN, OH, WV, PA, MD | 2,151 | Denver - Kansas City - St. Louis - Columbus | Mountain West to Mid-Atlantic |
| **I-80** | Northern transcontinental | CA, NV, UT, WY, NE, IA, IL, IN, OH, PA, NJ, NY | 2,899 | San Francisco - Chicago - New York | Major Northern medical corridor |
| **I-90** | Northern border route | WA, ID, MT, WY, SD, MN, WI, IL, IN, OH, PA, NY, MA | 3,020 | Seattle - Chicago - Boston | Longest interstate, connects major Northern cities |

### North-South Interstate Corridors

| Route | Description | States Traversed | Length (Miles) | Key Cities Connected | Healthcare Relevance |
|----|----|----|----|----|----|
| **I-5** | West Coast | CA, OR, WA | 1,381 | San Diego - Los Angeles - San Francisco - Portland - Seattle | Pacific Coast medical corridor |
| **I-15** | Southwestern | CA, NV, AZ, UT, ID, MT | 1,433 | San Diego - Las Vegas - Salt Lake City | Desert Southwest access |
| **I-25** | Mountain corridor | NM, CO, WY | 1,062 | Albuquerque - Denver - Cheyenne | Front Range medical access |
| **I-35** | Central Plains | TX, OK, KS, MO, IA, MN | 1,568 | Laredo - San Antonio - Austin - Dallas - Minneapolis | Texas to Twin Cities corridor |
| **I-65** | South Central | AL, TN, KY, IN | 887 | Mobile - Birmingham - Nashville - Louisville - Indianapolis | Connects Southern to Midwest medical centers |
| **I-75** | Eastern corridor | FL, GA, TN, KY, OH, MI | 1,786 | Miami - Atlanta - Cincinnati - Detroit | Major Eastern medical corridor |
| **I-85** | Southeastern | AL, GA, SC, NC, VA | 666 | Montgomery - Atlanta - Charlotte - Richmond | Southeast medical corridor |
| **I-95** | East Coast | ME, NH, MA, RI, CT, NY, NJ, PA, DE, MD, DC, VA, NC, SC, GA, FL | 1,908 | Miami - Savannah - Richmond - Washington - Philadelphia - New York - Boston | Primary East Coast medical corridor |

## Alternative Transportation Network Data Sources

| Data Source | Download URL | File Format | Coverage | Cost | Licensing | Quality Level |
|----|----|----|----|----|----|----|
| **OpenStreetMap (OSM)** | <https://www.openstreetmap.org/> | Various | Global | Free | Open Data License | High, community maintained |
| **HERE Maps Road Data** | <https://developer.here.com/> | API/Download | Global | Commercial | HERE License | Very High, commercial grade |
| **TomTom Road Network** | <https://developer.tomtom.com/> | API | Global | Commercial | TomTom License | Very High, commercial grade |

## Highway-Specific R Package Resources

| Package | Function | Data Included | Usage Example | Notes |
|----|----|----|----|----|
| **tigris** | `primary_roads()`, `primary_secondary_roads()` | Census TIGER roads | `tigris::primary_roads(cb = TRUE)` | Automatically downloads highways |
| **osmdata** | `opq()`, `add_osm_feature()` | OpenStreetMap data | `osmdata::opq("USA") %>% add_osm_feature("highway", "motorway")` | Query specific highway types |
| **tidytransit** | Transit and road network analysis | GTFS + road networks | Various | Public transportation integration |
| **dodgr** | Distance calculations on road networks | OSM road networks | Network analysis | Route optimization |

## Highway Data Download Examples

### Interstate Highways via tigris

``` r
# Download all primary roads (includes Interstates)
primary_roads <- tigris::primary_roads(cb = TRUE)

# Filter for Interstate highways only
interstates <- primary_roads %>%
  filter(stringr::str_detect(FULLNAME, "^I "))

# Specific Interstate (example: I-25)
i25 <- primary_roads %>%
  filter(stringr::str_detect(FULLNAME, "I 25"))
```

### Major Highways via OpenStreetMap

``` r
library(osmdata)

# Download Interstate highways
interstates_osm <- opq("United States") %>%
  add_osm_feature(key = "highway", value = "motorway") %>%
  add_osm_feature(key = "ref", value = c("I 95", "I 25", "I 70")) %>%
  osmdata_sf()

# Download US highways  
us_highways <- opq("United States") %>%
  add_osm_feature(key = "highway", value = "trunk") %>%
  add_osm_feature(key = "ref", value = c("US 50", "US 101")) %>%
  osmdata_sf()
```

### State-Specific Highway Downloads

``` r
# Colorado highways (example for I-25, I-70, I-76)
co_roads <- tigris::primary_secondary_roads(state = "CO", cb = TRUE)

co_interstates <- co_roads %>%
  filter(stringr::str_detect(FULLNAME, "^I ")) %>%
  filter(stringr::str_detect(FULLNAME, "I 25|I 70|I 76"))
```

## Highway Analysis Applications for Healthcare Accessibility

### Interstate Corridor Analysis

-   **I-95 Corridor**: East Coast medical referral patterns
-   **I-10 Corridor**: Southern transcontinental access
-   **I-25 Front Range**: Denver-Colorado Springs-Albuquerque medical corridor
-   **I-70 Mountain Corridor**: Mountain West healthcare access

### Highway Buffer Analysis

``` r
# Create buffers around major highways for accessibility analysis
highway_buffers <- interstates %>%
  st_buffer(dist = units::set_units(50, "miles"))  # 50-mile highway corridor
```

## Cancer Care and Specialty Medical Areas

| Geographic Unit | Data Source | Download URL | File Format | Coverage | Update Frequency | Notes |
|----|----|----|----|----|----|----|
| **NCI-Designated Cancer Centers** | National Cancer Institute | <https://www.cancer.gov/research/infrastructure/cancer-centers/find> | Point data (geocode addresses) | National | As designated | Comprehensive cancer centers |
| **CoC-Accredited Cancer Programs** | Commission on Cancer | <https://www.facs.org/quality-programs/cancer-programs/commission-cancer/coc-accredited-programs/> | Point data (geocode addresses) | National | Annual | Accredited cancer programs |
| **NCCN Member Institutions** | NCCN | <https://www.nccn.org/about/member-institutions> | Point data (geocode addresses) | National | As membership changes | Leading cancer centers |

## American Community Survey Geographic Summary Levels

| Geographic Unit | Summary Level Code | Download URL | File Format | Coverage | Update Frequency | Notes |
|----|----|----|----|----|----|----|
| **Nation** | 010 | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | US | Annual | National boundary |
| **Regions** | 020 | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | US | Annual | 4 Census regions |
| **Divisions** | 030 | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | US | Annual | 9 Census divisions |
| **States** | 040 | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | US | Annual | 50 states + DC |
| **Counties** | 050 | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | US | Annual | \~3,100 counties |
| **County Subdivisions** | 060 | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | US | Annual | Townships, boroughs, etc. |
| **Census Tracts** | 140 | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | US | Annual | \~74,000 tracts |
| **Block Groups** | 150 | <https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html> | Shapefile | US | Annual | \~220,000 block groups |

## Special R Package Resources for Geographic Data

| Package | Function | Data Included | Usage | Notes |
|----|----|----|----|----|
| **tigris** | `states()`, `counties()`, `tracts()`, `block_groups()` | All Census boundaries | `tigris::states(cb = TRUE)` | Automatically downloads and caches |
| **tidycensus** | `get_acs(..., geometry = TRUE)` | Census data + boundaries | `get_acs(geography = "tract", geometry = TRUE)` | Data and geography combined |
| **sf** | Spatial data processing | \- | `st_read("shapefile.shp")` | Core spatial analysis |
| **USAboundaries** | Historical US boundaries | Counties, states (1629-2000) | `us_states(map_date = "2000-01-01")` | Historical analysis |
| **spData** | Spatial datasets | Various example datasets | `data(us_states)` | Teaching and examples |

## File Download Examples and R Code

### Census Boundaries via tigris Package

``` r
# Download state boundaries
states_sf <- tigris::states(cb = TRUE, resolution = "20m")

# Download census tracts for specific state  
tracts_sf <- tigris::tracts(state = "CO", cb = TRUE)

# Download block groups for specific county
bg_sf <- tigris::block_groups(state = "CO", county = "001", cb = TRUE)
```

### HRSA Data Download

``` r
# Download HPSA data
hpsa_url <- "https://data.hrsa.gov/data/download/hrsa-hpsa-primary-care-shortage-areas.csv"
hpsa_data <- readr::read_csv(hpsa_url)
```

## Data Vintage and Compatibility Notes

| Geographic Unit | 2010 Census Vintage | 2020 Census Vintage | Compatibility Issues |
|----|----|----|----|
| **Census Tracts** | \~74,000 tracts | \~84,000 tracts | Tract boundaries changed significantly |
| **Block Groups** | \~217,000 BGs | \~242,000 BGs | Many boundary changes |
| **Counties** | 3,143 counties | 3,143 counties | Stable boundaries |
| **States** | 50 + DC | 50 + DC | No changes |
| **ZCTAs** | 2010 ZIP patterns | 2020 ZIP patterns | Significant changes in suburban areas |

# License

MIT (allows commercial and academic use with attribution)

# 🤝 Contributing

We welcome contributions!

# 📜 Citation

If you use this work in your research, please cite:

``` bibtex
@misc{muffly2025gynoncaccess,
  title={Gynecologic Oncology Accessibility Project: Nationwide Analysis of Access to OBGYN Subspecialists Using Drive Time Isochrones (2013-2023)},
  author={Muffly, Tyler},
  year={2025},
  url={https://github.com/mufflyt/isochrones},
  note={Version 2.0.0}
}
```

# Contact

**Primary Contact**: Tyler Muffly, MD\
**Email**: [tyler.muffly\@dhha.org](mailto:tyler.muffly@dhha.org){.email}\
**GitHub**: <https://github.com/mufflyt/isochrones>

# Project Maintenance Schedule

-   **Annual Updates**: New NPPES data release (typically March)
-   **API Monitoring**: Monthly checks of rate limits and costs
-   **Data Validation**: Biannual review of provider lists
-   **Code Updates**: As needed for R package changes

# 

======= Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the "Software"), to
deal in the Software without restriction, including without limitation the
rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is furnished
to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

```         

## Citation Guidelines

### **Academic Citation**
```

Muffly, T. (2025). Comprehensive Healthcare Accessibility Analysis: Gynecologic
Oncology Access Using Drive Time Isochrone Methodology. GitHub Repository.
<https://github.com/mufflyt/isochrones>

```         

### **BibTeX Entry**

```bibtex
@misc{muffly2025accessibility,
  title={Comprehensive Healthcare Accessibility Analysis: Gynecologic Oncology Access Using Drive Time Isochrone Methodology},
  author={Muffly, Tyler},
  year={2025},
  url={https://github.com/mufflyt/isochrones},
  note={Comprehensive analysis of nationwide access to gynecologic oncologists using drive time isochrones, demographic data, and geospatial analysis}
}
```

--------------------------------------------------------------------------------

# 🙏 Acknowledgments

::: highlight-box
### **Data Sources and Institutional Support**

-   **National Bureau of Economic Research (NBER)** - Historical NPPES data
    access
-   **Centers for Medicare & Medicaid Services (CMS)** - Provider validation
    data
-   **HERE Technologies** - Geocoding and routing API access\
-   **U.S. Census Bureau** - Demographic and geographic data
-   **Denver Health and Hospital Authority**

### **Technical Infrastructure**

-   **R Core Team and CRAN Contributors** - Open source statistical computing
    platform
-   **RStudio** - Integrated development environment
-   **Tidyverse** - Comprehensive data science ecosystem
-   **Spatial R Community** - Geospatial analysis packages and support

### **Research Community**

-   **Health Services Research Community** - Methodological guidance and peer
    review
-   **Geographic Information Science Community** - Spatial analysis techniques
-   **Open Science Advocates** - Reproducible research principles and practices
:::

--------------------------------------------------------------------------------

*This comprehensive healthcare accessibility analysis represents ongoing
research into geographic disparities in specialty healthcare access. The
methodology and findings are continuously updated with new provider and
demographic data to maintain relevance for healthcare policy and planning
decisions.*

--------------------------------------------------------------------------------

::: {style="text-align: center; margin-top: 50px; padding: 20px; background-color: #f8f9fa; border-radius: 10px;"}
**🏥 Improving Healthcare Access Through Data-Driven Analysis 📊**

*Generated on `r Sys.Date()` \| Version 2.0 \| Comprehensive HTML Documentation*
:::
